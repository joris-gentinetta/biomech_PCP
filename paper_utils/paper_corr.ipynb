{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:16:27.387502Z",
     "start_time": "2024-08-23T23:16:27.384686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import (\n",
    "    participants,\n",
    "    recordings,\n",
    "    targets,\n",
    "    test_recordings,\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.width\", 200)  # Total width of the display\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.max_colwidth\", None)  # Don't truncate column contents\n",
    "pd.set_option(\"display.max_rows\", None)  # Don't truncate column contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e82aa195391fae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:16:27.864734Z",
     "start_time": "2024-08-23T23:16:27.860617Z"
    }
   },
   "outputs": [],
   "source": [
    "movements = recordings + test_recordings\n",
    "# data_folder = Path('/home/haptix/haptix/biomech_PCP/paper_utils/paper_data/trajectories')\n",
    "data_folder = Path(\"/home/haptix/haptix/biomech_PCP/paper_utils/paper_data/predictions\")\n",
    "\n",
    "ptcID = {\n",
    "    \"P_149\": \"P1\",\n",
    "    \"P_238\": \"P2\",\n",
    "    \"P_407\": \"P3\",\n",
    "    \"P_426\": \"P4\",\n",
    "    \"P_577\": \"P5\",\n",
    "    \"P_668\": \"P6\",\n",
    "    \"P_711\": \"P7\",\n",
    "    \"P_950\": \"P8\",\n",
    "    \"P7_453\": \"A1\",\n",
    "    \"P6_820\": \"A2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "corr_rows = []\n",
    "mse_rows = []\n",
    "\n",
    "for perturb in [True, False]:\n",
    "    for condition in [\"before\", \"after\"]:\n",
    "        for participant in participants:\n",
    "            gt_cat_new = []\n",
    "            pred_cat_new = []\n",
    "            gt_cat_known = []\n",
    "            pred_cat_known = []\n",
    "            gt_cat = []\n",
    "            pred_cat = []\n",
    "\n",
    "            for movement in movements:\n",
    "                pred = pd.read_parquet(\n",
    "                    data_folder\n",
    "                    / participant\n",
    "                    / f\"perturbed_{perturb}-pred_{movement}_{condition}.parquet\"\n",
    "                )\n",
    "                gt = pd.read_parquet(\n",
    "                    data_folder / participant / f\"target_{movement}_{condition}.parquet\"\n",
    "                )\n",
    "\n",
    "                mse = np.mean((gt - pred) ** 2, axis=0)\n",
    "                mse_row = {\n",
    "                    \"Participant\": participant,\n",
    "                    \"Perturb\": perturb,\n",
    "                    \"Condition\": condition,\n",
    "                    \"Movement\": movement,\n",
    "                    \"MSE\": np.mean(mse),\n",
    "                }\n",
    "                mse_rows.append(mse_row)\n",
    "\n",
    "                gt_cat.append(gt)\n",
    "                pred_cat.append(pred)\n",
    "                if movement in recordings:\n",
    "                    gt_cat_known.append(gt)\n",
    "                    pred_cat_known.append(pred)\n",
    "                elif movement in test_recordings:\n",
    "                    gt_cat_new.append(gt)\n",
    "                    pred_cat_new.append(pred)\n",
    "\n",
    "            # Concatenate across all movements for correlation\n",
    "            gt_cat = np.concatenate(gt_cat, axis=0)\n",
    "            pred_cat = np.concatenate(pred_cat, axis=0)\n",
    "            gt_cat_known = np.concatenate(gt_cat_known, axis=0)\n",
    "            pred_cat_known = np.concatenate(pred_cat_known, axis=0)\n",
    "            gt_cat_new = np.concatenate(gt_cat_new, axis=0)\n",
    "            pred_cat_new = np.concatenate(pred_cat_new, axis=0)\n",
    "\n",
    "            for i, target in enumerate(targets):\n",
    "                corr = np.corrcoef(gt_cat[:, i], pred_cat[:, i])[0, 1]\n",
    "                corr_known = np.corrcoef(gt_cat_known[:, i], pred_cat_known[:, i])[0, 1]\n",
    "                corr_new = np.corrcoef(gt_cat_new[:, i], pred_cat_new[:, i])[0, 1]\n",
    "                corr_row = {\n",
    "                    \"Participant\": participant,\n",
    "                    \"Perturb\": perturb,\n",
    "                    \"Condition\": condition,\n",
    "                    \"Target\": target,\n",
    "                    \"Type\": \"Combined\",\n",
    "                    \"Correlation\": corr,\n",
    "                }\n",
    "                corr_rows.append(corr_row)\n",
    "                corr_row = {\n",
    "                    \"Participant\": participant,\n",
    "                    \"Perturb\": perturb,\n",
    "                    \"Condition\": condition,\n",
    "                    \"Target\": target,\n",
    "                    \"Type\": \"Known\",\n",
    "                    \"Correlation\": corr_known,\n",
    "                }\n",
    "                corr_rows.append(corr_row)\n",
    "                corr_row = {\n",
    "                    \"Participant\": participant,\n",
    "                    \"Perturb\": perturb,\n",
    "                    \"Condition\": condition,\n",
    "                    \"Target\": target,\n",
    "                    \"Type\": \"New\",\n",
    "                    \"Correlation\": corr_new,\n",
    "                }\n",
    "                corr_rows.append(corr_row)\n",
    "\n",
    "\n",
    "# Create final long-form dataframes\n",
    "df_corr = pd.DataFrame(corr_rows)\n",
    "df_mse = pd.DataFrame(mse_rows)\n",
    "\n",
    "# Optional: save\n",
    "df_corr.to_csv(\"all_correlation_results.csv\", index=False)\n",
    "df_mse.to_csv(\"all_mse_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3edcd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for correlation tables!\n",
    "def df_to_latex(df, caption, label):\n",
    "    col_names = list(df.columns)\n",
    "    # col_names.replace('Mean Correlation', 'Mean Corr.')\n",
    "    # col_names.replace('Mean Transformed Correlation', 'Mean Transformed Corr.')\n",
    "    # Create LaTeX column format string (e.g., \"|l|ccc|\")\n",
    "    col_format = \"|l|\" + \"c\" * (len(col_names) - 1) + \"|\"\n",
    "\n",
    "    # Create header row\n",
    "    header_row = \" & \".join(col_names) + \" \\\\\\\\\"\n",
    "\n",
    "    # we want to go in ascending order of participants\n",
    "    # df = df.sort_values(by='Participant')\n",
    "\n",
    "    # Create data rows\n",
    "    data_rows = \"\\n\".join(\n",
    "        \" & \".join([str(row[0])] + [f\"{val:.3f}\" for val in row[1:]]) + \" \\\\\\\\\"\n",
    "        for index, row in df.iterrows()\n",
    "    )\n",
    "\n",
    "    latex_str = f\"\"\"\\\\begin{{table}}[ht]\n",
    "    \\\\caption{{{caption}}}\n",
    "    \\\\label{{{label}}}\n",
    "    \\\\centering\n",
    "    \\\\resizebox{{\\\\textwidth}}{{!}}{{%\n",
    "    \\\\begin{{tabular}}{{{col_format}}}\n",
    "        \\\\hline\n",
    "        {header_row}\n",
    "        \\\\hline\n",
    "        {data_rows}\n",
    "        \\\\hline\n",
    "    \\\\end{{tabular}}\n",
    "    }}\n",
    "\\\\end{{table}}\"\"\"\n",
    "\n",
    "    return latex_str\n",
    "\n",
    "\n",
    "# for MSE tables!\n",
    "def df_to_latex_split(df, caption, label):\n",
    "    # Split main movement columns from mean summary columns\n",
    "    df = df.sort_values(by=\"Participant\")\n",
    "    mean_cols = [col for col in df.columns if \"Mean\" in col]\n",
    "\n",
    "    # Format the main table\n",
    "    header_main = \" & \".join([\"\\\\textbf{Participant}\"] + movements) + \" \\\\\\\\\"\n",
    "    rows_main = \"\\n\".join(\n",
    "        \" & \".join([str(row[\"Participant\"])] + [f\"{row[col]:.3f}\" for col in movements])\n",
    "        + \" \\\\\\\\\"\n",
    "        for _, row in df.iterrows()\n",
    "    )\n",
    "\n",
    "    # Format the smaller table\n",
    "    header_summary = (\n",
    "        \" & \".join(\n",
    "            [\"\\\\textbf{Participant}\"] + [f\"\\\\textbf{{{col}}}\" for col in mean_cols]\n",
    "        )\n",
    "        + \" \\\\\\\\\"\n",
    "    )\n",
    "    rows_summary = \"\\n\".join(\n",
    "        \" & \".join([str(row[\"Participant\"])] + [f\"{row[col]:.3f}\" for col in mean_cols])\n",
    "        + \" \\\\\\\\\"\n",
    "        for _, row in df.iterrows()\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "\\\\begin{{table}}[ht!]\n",
    "    \\\\caption{{{caption}}}\n",
    "    \\\\label{{{label}}}\n",
    "    \\\\centering\n",
    "    \\\\resizebox{{\\\\textwidth}}{{!}}{{%\n",
    "    \\\\begin{{tabular}}{{|l|{\"c\" * len(movements)}|}}\n",
    "        \\\\hline\n",
    "        {header_main}\n",
    "        \\\\hline\n",
    "        {rows_main}\n",
    "        \\\\hline\n",
    "    \\\\end{{tabular}}\n",
    "    }}\\\\\\\\[1em]\n",
    "    \\\\begin{{scriptsize}}\n",
    "    \\\\begin{{tabular}}{{|l|{\"c\" * len(mean_cols)}|}}\n",
    "        \\\\hline\n",
    "        {header_summary}\n",
    "        \\\\hline\n",
    "        {rows_summary}\n",
    "        \\\\hline\n",
    "    \\\\end{{tabular}}\n",
    "    \\\\end{{scriptsize}}\n",
    "\\\\end{{table}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08728b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the MSE dataframes as appropriate\n",
    "df_mse = pd.read_csv(\"all_mse_results.csv\")\n",
    "\n",
    "mse_str = \"\"\"\"\"\"\n",
    "\n",
    "desiredOrder = [(False, \"before\"), (False, \"after\"), (True, \"before\"), (True, \"after\")]\n",
    "# for perturb in [True, False]:\n",
    "#     for condition in ['before', 'after']:\n",
    "for perturb, condition in desiredOrder:\n",
    "    df = df_mse[(df_mse[\"Perturb\"] == perturb) & (df_mse[\"Condition\"] == condition)]\n",
    "    df = df.pivot(index=\"Participant\", columns=\"Movement\", values=\"MSE\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename_axis(None, axis=1)  # Remove the name of the columns index\n",
    "    # rename the participant IDs to their numbers\n",
    "    df[\"Participant\"] = df[\"Participant\"].map(ptcID).fillna(df[\"Participant\"])\n",
    "    df.sort_values(by=\"Participant\", inplace=True)\n",
    "\n",
    "    # Calculate mean across all movements\n",
    "    df[\"Mean Combined Movements\"] = df.loc[:, movements].mean(axis=1)\n",
    "    # Calculate mean across known movements\n",
    "    df[\"Mean Known Movements\"] = df.loc[:, recordings].mean(axis=1)\n",
    "    # Calculate mean across new movements\n",
    "    df[\"Mean New Movements\"] = df.loc[:, test_recordings].mean(axis=1)\n",
    "\n",
    "    # Save the dataframe\n",
    "    df.to_csv(f\"mse_results_{perturb}_{condition}.csv\", index=False)\n",
    "\n",
    "    captions = {\n",
    "        (True, \"before\"): \"MSE for each movement (With Perturbations)\",\n",
    "        (True, \"after\"): \"MSE for each movement (After Learning Perturbations)\",\n",
    "        (False, \"before\"): \"MSE for each movement (After Initial Training)\",\n",
    "        (False, \"after\"): \"MSE for each movement (After Online Training)\",\n",
    "    }\n",
    "\n",
    "    label = f\"tab:mse_{perturb}_{condition}\"\n",
    "\n",
    "    # Create a string representation of the dataframe\n",
    "    thisString = df_to_latex_split(df, captions[(perturb, condition)], label)\n",
    "    mse_str += thisString + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e85177",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1687bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the corr dataframes as appropriate\n",
    "df_corr = pd.read_csv(\"all_correlation_results.csv\")\n",
    "\n",
    "corr_str = \"\"\"\"\"\"\n",
    "\n",
    "desiredOrder = [(False, \"before\"), (False, \"after\"), (True, \"before\"), (True, \"after\")]\n",
    "movementTypes = [\"Combined\", \"Known\", \"New\"]\n",
    "desiredOrder = [\n",
    "    (movementType, perturb, condition)\n",
    "    for movementType in movementTypes\n",
    "    for perturb, condition in desiredOrder\n",
    "]\n",
    "for movementType, perturb, condition in desiredOrder:\n",
    "    df = df_corr[\n",
    "        (df_corr[\"Perturb\"] == perturb)\n",
    "        & (df_corr[\"Condition\"] == condition)\n",
    "        & (df_corr[\"Type\"] == movementType)\n",
    "    ]\n",
    "    df = df.pivot(index=\"Participant\", columns=\"Target\", values=\"Correlation\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename_axis(None, axis=1)  # Remove the name of the columns index\n",
    "    # rename the participant IDs to their numbers\n",
    "    df[\"Participant\"] = df[\"Participant\"].map(ptcID).fillna(df[\"Participant\"])\n",
    "    df.sort_values(by=\"Participant\", inplace=True)\n",
    "\n",
    "    # do a fisher transformation on the correlations\n",
    "    transformed_corr = np.arctanh(df.loc[:, targets])\n",
    "\n",
    "    mean_transformed_corr = transformed_corr.mean(axis=1)\n",
    "    # apply the inverse fisher transformation to get back to correlation space\n",
    "\n",
    "    # Calculate mean across all movements\n",
    "    # df['Mean Correlation'] = df.loc[:, targets].mean(axis=1)\n",
    "    df[\"Mean Correlation\"] = np.tanh(mean_transformed_corr)\n",
    "\n",
    "    # add an extra row that is the mean across all participants\n",
    "    mean_row = df.loc[df[\"Participant\"].str.startswith(\"A\"), targets].mean()\n",
    "    mean_transform = (\n",
    "        transformed_corr.loc[df[\"Participant\"].str.startswith(\"A\")].mean().mean()\n",
    "    )\n",
    "    mean_row[\"Participant\"] = \"Amputees\"\n",
    "    # mean_row['Mean Correlation'] = mean_row.loc[targets].mean()\n",
    "    mean_row[\"Mean Correlation\"] = np.tanh(mean_transform)\n",
    "\n",
    "    mean_row_ = df.loc[df[\"Participant\"].str.startswith(\"P\"), targets].mean()\n",
    "    mean_transform_ = (\n",
    "        transformed_corr.loc[df[\"Participant\"].str.startswith(\"P\")].mean().mean()\n",
    "    )\n",
    "    mean_row_[\"Participant\"] = \"Intact\"\n",
    "    # mean_row_['Mean Correlation'] = mean_row_.loc[targets].mean()\n",
    "    mean_row_[\"Mean Correlation\"] = np.tanh(mean_transform_)\n",
    "\n",
    "    df = pd.concat(\n",
    "        [df, mean_row.to_frame().T, mean_row_.to_frame().T], ignore_index=True\n",
    "    )\n",
    "\n",
    "    df.to_csv(\n",
    "        f\"correlation_results_{perturb}_{condition}_{movementType}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    captions = {\n",
    "        (\n",
    "            True,\n",
    "            \"before\",\n",
    "        ): f\"{movementType} Movements Correlation Results (With Perturbations)\",\n",
    "        (\n",
    "            True,\n",
    "            \"after\",\n",
    "        ): f\"{movementType} Movements Correlation Results (After Learning Perturbations)\",\n",
    "        (\n",
    "            False,\n",
    "            \"before\",\n",
    "        ): f\"{movementType} Movements Correlation Results (After Initial Training)\",\n",
    "        (\n",
    "            False,\n",
    "            \"after\",\n",
    "        ): f\"{movementType} Movements Correlation Results (After Online Training)\",\n",
    "    }\n",
    "\n",
    "    label = f\"tab:corr_{movementType}_{perturb}_{condition}\"\n",
    "\n",
    "    # Create a string representation of the dataframe\n",
    "    thisString = df_to_latex(df, captions[(perturb, condition)], label)\n",
    "    corr_str += thisString + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51066d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fe184e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Condition  Test Set  Statistic   p-value  Effect Size\n",
      "0             Online Training  Combined        0.0  0.001953    -1.000000\n",
      "4             Online Training     Known       23.0  0.695312     0.163636\n",
      "8             Online Training       New        0.0  0.001953    -1.000000\n",
      "1      Learning Perturbations  Combined        0.0  0.001953    -1.000000\n",
      "5      Learning Perturbations     Known        0.0  0.001953    -1.000000\n",
      "9      Learning Perturbations       New        0.0  0.001953    -1.000000\n",
      "2   Pre-Perturbation Baseline  Combined        9.0  0.064453    -0.672727\n",
      "6   Pre-Perturbation Baseline     Known        4.0  0.013672     0.854545\n",
      "10  Pre-Perturbation Baseline       New        0.0  0.001953    -1.000000\n",
      "3      Perturbation Breakdowm  Combined        0.0  0.001953     1.000000\n",
      "7      Perturbation Breakdowm     Known        0.0  0.001953     1.000000\n",
      "11     Perturbation Breakdowm       New        4.0  0.013672     0.854545\n",
      "                    Condition  Test Set  Statistic   p-value  Effect Size\n",
      "0             Online Training  Combined        0.0  0.001953    -1.000000\n",
      "4             Online Training     Known       23.0  0.695312     0.163636\n",
      "8             Online Training       New        0.0  0.001953    -1.000000\n",
      "1      Learning Perturbations  Combined        0.0  0.001953    -1.000000\n",
      "5      Learning Perturbations     Known        0.0  0.001953    -1.000000\n",
      "9      Learning Perturbations       New        0.0  0.001953    -1.000000\n",
      "2   Pre-Perturbation Baseline  Combined        9.0  0.064453    -0.672727\n",
      "6   Pre-Perturbation Baseline     Known        4.0  0.013672     0.854545\n",
      "10  Pre-Perturbation Baseline       New        0.0  0.001953    -1.000000\n",
      "3      Perturbation Breakdowm  Combined        0.0  0.001953     1.000000\n",
      "7      Perturbation Breakdowm     Known        0.0  0.001953     1.000000\n",
      "11     Perturbation Breakdowm       New        4.0  0.013672     0.854545\n"
     ]
    }
   ],
   "source": [
    "# we also want to perform some statistical tests to compare the MSE between conditions\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "# we want to perfrom these on the means between different conditions\n",
    "def perform_wilcoxon_test(df1, df2):\n",
    "    # Perform Wilcoxon signed-rank test\n",
    "    stat, p_value = wilcoxon(df1, df2)\n",
    "    # rank_biserial_effect_size = stat / (len(df1) * (len(df1) + 1) / 2)  # Calculate rank-biserial effect size\n",
    "    diffs = df2 - df1\n",
    "    ranks = abs(diffs).rank()\n",
    "    W_pos = ranks[diffs > 0].sum()\n",
    "    W_neg = ranks[diffs < 0].sum()\n",
    "    n = len(diffs)\n",
    "    r_rb = (W_pos - W_neg) / (n * (n + 1) / 2)\n",
    "    return stat, p_value, r_rb\n",
    "\n",
    "\n",
    "# Perform all tests and collect output\n",
    "results = []\n",
    "\n",
    "# we want to make the comparisons between:\n",
    "# 1) After Initial Training to After Online Training\n",
    "# 2) With Perturbation to After Learning Perturbations\n",
    "# 3) After Initial Training to With Perturbation\n",
    "# 4) After Initial Training to After Learning Perturbations\n",
    "# for each of the three movement types (Combined, Known, New)\n",
    "\n",
    "df_AIT = pd.read_csv(\"mse_results_False_before.csv\")\n",
    "df_AOT = pd.read_csv(\"mse_results_False_after.csv\")\n",
    "df_WP = pd.read_csv(\"mse_results_True_before.csv\")\n",
    "df_ALP = pd.read_csv(\"mse_results_True_after.csv\")\n",
    "\n",
    "for movement_type in [\n",
    "    \"Mean Combined Movements\",\n",
    "    \"Mean Known Movements\",\n",
    "    \"Mean New Movements\",\n",
    "]:\n",
    "    type = movement_type.replace(\"Mean \", \"\").replace(\" Movements\", \"\")\n",
    "    # Compare After Initial Training to After Online Training\n",
    "    stat, p_value, effect_size = perform_wilcoxon_test(\n",
    "        df_AIT[movement_type], df_AOT[movement_type]\n",
    "    )\n",
    "    results.append(\n",
    "        {\n",
    "            \"Condition\": \"Online Training\",\n",
    "            \"Test Set\": type,\n",
    "            \"Statistic\": stat,\n",
    "            \"p-value\": p_value,\n",
    "            \"Effect Size\": effect_size,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Compare With Perturbation to After Learning Perturbations\n",
    "    stat, p_value, effect_size = perform_wilcoxon_test(\n",
    "        df_WP[movement_type], df_ALP[movement_type]\n",
    "    )\n",
    "    results.append(\n",
    "        {\n",
    "            \"Condition\": \"Learning Perturbations\",\n",
    "            \"Test Set\": type,\n",
    "            \"Statistic\": stat,\n",
    "            \"p-value\": p_value,\n",
    "            \"Effect Size\": effect_size,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Compare After Initial Training to After Learning Perturbations\n",
    "    stat, p_value, effect_size = perform_wilcoxon_test(\n",
    "        df_AIT[movement_type], df_ALP[movement_type]\n",
    "    )\n",
    "    results.append(\n",
    "        {\n",
    "            \"Condition\": \"Pre-Perturbation Baseline\",\n",
    "            \"Test Set\": type,\n",
    "            \"Statistic\": stat,\n",
    "            \"p-value\": p_value,\n",
    "            \"Effect Size\": effect_size,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Compare After Initial Training to With Perturbation\n",
    "    stat, p_value, effect_size = perform_wilcoxon_test(\n",
    "        df_AIT[movement_type], df_WP[movement_type]\n",
    "    )\n",
    "    results.append(\n",
    "        {\n",
    "            \"Condition\": \"Perturbation Breakdowm\",\n",
    "            \"Test Set\": type,\n",
    "            \"Statistic\": stat,\n",
    "            \"p-value\": p_value,\n",
    "            \"Effect Size\": effect_size,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "df_results = pd.DataFrame(results)\n",
    "# Save the results to a CSV file\n",
    "df_results.to_csv(\"wilcoxon_results.csv\", index=False)\n",
    "\n",
    "# reorder the table to group the conditions\n",
    "df_results[\"Condition\"] = pd.Categorical(\n",
    "    df_results[\"Condition\"],\n",
    "    categories=[\n",
    "        \"Online Training\",\n",
    "        \"Learning Perturbations\",\n",
    "        \"Pre-Perturbation Baseline\",\n",
    "        \"Perturbation Breakdowm\",\n",
    "    ],\n",
    "    ordered=True,\n",
    ")\n",
    "df_results.sort_values(by=[\"Condition\", \"Test Set\"], inplace=True)\n",
    "print(df_results)\n",
    "df_results.to_csv(\"wilcoxon_results.csv\", index=False)\n",
    "\n",
    "latex_results = df_results.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Wilcoxon Signed-Rank Test Results for MSE Comparisons\",\n",
    "    label=\"tab:wilcoxon_results\",\n",
    "    column_format=\"|l l c c c|\",\n",
    "    escape=False,\n",
    "    float_format=\"%.3f\",\n",
    ")\n",
    "# Print the results DataFrame\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
