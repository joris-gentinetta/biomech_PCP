{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:16:27.387502Z",
     "start_time": "2024-08-23T23:16:27.384686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from utils import (\n",
    "    amputees,\n",
    "    channel_names,\n",
    "    intact,\n",
    "    participants,\n",
    "    recordings,\n",
    "    targets,\n",
    "    test_recordings,\n",
    ")\n",
    "\n",
    "pd.set_option('display.width', 200)          # Total width of the display\n",
    "pd.set_option('display.max_columns', None)   # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Don't truncate column contents\n",
    "pd.set_option('display.max_rows', None)  # Don't truncate column contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e82aa195391fae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:16:27.864734Z",
     "start_time": "2024-08-23T23:16:27.860617Z"
    }
   },
   "outputs": [],
   "source": [
    "movements = recordings + test_recordings\n",
    "data_folder = Path('/home/haptix/haptix/biomech_PCP/paper_utils/paper_data/trajectories')\n",
    "\n",
    "ptcID = {\n",
    "    'P_149': 'P1',\n",
    "    'P_238': 'P2',\n",
    "    'P_407': 'P3',\n",
    "    'P_426': 'P4',\n",
    "    'P_577': 'P5',\n",
    "    'P_668': 'P6',\n",
    "    'P_711': 'P7',\n",
    "    'P_950': 'P8',\n",
    "    'P7_453': 'A1',\n",
    "    'P6_820': 'A2',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08527872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will read the data from each participant and movement and calculate correlations and MSE by movement\n",
    "online_participants = [part for part in participants if 'P6' not in part]\n",
    "for perturb in [True, False]:\n",
    "    for condition in ['before', 'after']:\n",
    "        df_mse = pd.DataFrame(index=online_participants, columns=movements); df_mse.loc[:, 'Participant'] = df_mse.index\n",
    "        df_corr = pd.DataFrame(index=online_participants, columns=targets); df_corr.loc[:, 'Participant'] = df_corr.index\n",
    "        for participant in online_participants:\n",
    "            gt_cat = []\n",
    "            pred_cat = []\n",
    "            for movement in movements:\n",
    "                gt = np.load(data_folder / participant / movement / 'GT/pred.npy'); gt_cat.append(gt)\n",
    "                pred = np.load(data_folder / participant / movement / f'perturb_{str(perturb)}/{condition}_online/pred.npy'); pred_cat.append(pred)\n",
    "\n",
    "                mse = np.mean((gt - pred) ** 2, axis=0)\n",
    "                df_mse.loc[participant, movement] = np.mean(mse)\n",
    "            \n",
    "            gt_cat = np.concatenate(gt_cat, axis=0)\n",
    "            pred_cat = np.concatenate(pred_cat, axis=0)\n",
    "\n",
    "            for i, target in enumerate(targets):\n",
    "                corr = np.corrcoef(gt_cat[:, i], pred_cat[:, i])[0, 1]\n",
    "                df_corr.loc[participant, target] = corr\n",
    "\n",
    "        # Save the results to CSV files\n",
    "        save_name = ('non_' if not perturb else '') + 'perturbed_' + condition + 'Online'\n",
    "        df_mse.to_csv(f'MSE_{save_name}.csv')\n",
    "        df_corr.to_csv(f'corr_{save_name}.csv')\n",
    "        # print(f'Participant {participant} - Perturbation: {perturb}, Condition: {condition} - MSE and Correlation calculated.')\n",
    "        # print(df_mse)\n",
    "        # print(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce004f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "mse_rows = []\n",
    "corr_rows = []\n",
    "\n",
    "# online_participants = [part for part in participants if 'P6' not in part]\n",
    "online_participants = participants\n",
    "\n",
    "for perturb in [True, False]:\n",
    "    for condition in ['before', 'after']:\n",
    "        for participant in online_participants:\n",
    "            if 'P6_' in participant and condition == 'after':\n",
    "                continue\n",
    "            gt_cat = []\n",
    "            pred_cat = []\n",
    "            for movement in movements:\n",
    "                gt = np.load(data_folder / participant / movement / 'GT/pred.npy')\n",
    "                pred = np.load(data_folder / participant / movement / f'perturb_{str(perturb)}/{condition}_online/pred.npy')\n",
    "\n",
    "                gt_cat.append(gt)\n",
    "                pred_cat.append(pred)\n",
    "\n",
    "                mse = np.mean((gt - pred) ** 2, axis=0)\n",
    "                mse_row = {\n",
    "                    'Participant': participant,\n",
    "                    'Perturb': perturb,\n",
    "                    'Condition': condition,\n",
    "                    'Movement': movement,\n",
    "                    'MSE': np.mean(mse)\n",
    "                }\n",
    "                mse_rows.append(mse_row)\n",
    "\n",
    "            # Concatenate across all movements for correlation\n",
    "            gt_cat = np.concatenate(gt_cat, axis=0)\n",
    "            pred_cat = np.concatenate(pred_cat, axis=0)\n",
    "\n",
    "            for i, target in enumerate(targets):\n",
    "                corr = np.corrcoef(gt_cat[:, i], pred_cat[:, i])[0, 1]\n",
    "                corr_row = {\n",
    "                    'Participant': participant,\n",
    "                    'Perturb': perturb,\n",
    "                    'Condition': condition,\n",
    "                    'Target': target,\n",
    "                    'Correlation': corr\n",
    "                }\n",
    "                corr_rows.append(corr_row)\n",
    "\n",
    "# Create final long-form dataframes\n",
    "df_mse = pd.DataFrame(mse_rows)\n",
    "df_corr = pd.DataFrame(corr_rows)\n",
    "\n",
    "# Optional: save\n",
    "df_mse.to_csv('all_mse_results.csv', index=False)\n",
    "df_corr.to_csv('all_correlation_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "591bd3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping participant P6_820 for perturbation True and condition after\n",
      "Skipping participant P6_820 for perturbation False and condition after\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "corr_rows = []\n",
    "corr_rows_known = []\n",
    "corr_rows_new = []\n",
    "\n",
    "# online_participants = [part for part in participants if 'P6' not in part]\n",
    "online_participants = participants # i guess P6 was in here?\n",
    "\n",
    "\n",
    "for perturb in [True, False]:\n",
    "    for condition in ['before', 'after']:\n",
    "        for participant in online_participants:\n",
    "            if 'P6_' in participant and condition == 'after':\n",
    "                print(f'Skipping participant {participant} for perturbation {perturb} and condition {condition}')\n",
    "                continue\n",
    "            gt_cat_new = []\n",
    "            pred_cat_new = []\n",
    "            gt_cat_known = []\n",
    "            pred_cat_known = []\n",
    "            gt_cat = []\n",
    "            pred_cat = []\n",
    "\n",
    "            for movement in movements:\n",
    "                gt = np.load(data_folder / participant / movement / 'GT/pred.npy')\n",
    "                pred = np.load(data_folder / participant / movement / f'perturb_{str(perturb)}/{condition}_online/pred.npy')\n",
    "\n",
    "                gt_cat.append(gt)\n",
    "                pred_cat.append(pred)\n",
    "                if movement in recordings:\n",
    "                    gt_cat_known.append(gt)\n",
    "                    pred_cat_known.append(pred)\n",
    "                elif movement in test_recordings:\n",
    "                    gt_cat_new.append(gt)\n",
    "                    pred_cat_new.append(pred)\n",
    "\n",
    "            # Concatenate across all movements for correlation\n",
    "            gt_cat = np.concatenate(gt_cat, axis=0)\n",
    "            pred_cat = np.concatenate(pred_cat, axis=0)\n",
    "            gt_cat_known = np.concatenate(gt_cat_known, axis=0)\n",
    "            pred_cat_known = np.concatenate(pred_cat_known, axis=0)\n",
    "            gt_cat_new = np.concatenate(gt_cat_new, axis=0)\n",
    "            pred_cat_new = np.concatenate(pred_cat_new, axis=0)\n",
    "\n",
    "            for i, target in enumerate(targets):\n",
    "                corr = np.corrcoef(gt_cat[:, i], pred_cat[:, i])[0, 1]\n",
    "                corr_known = np.corrcoef(gt_cat_known[:, i], pred_cat_known[:, i])[0, 1]\n",
    "                corr_new = np.corrcoef(gt_cat_new[:, i], pred_cat_new[:, i])[0, 1]\n",
    "                corr_row = {\n",
    "                    'Participant': participant,\n",
    "                    'Perturb': perturb,\n",
    "                    'Condition': condition,\n",
    "                    'Target': target,\n",
    "                    'Correlation': corr\n",
    "                }\n",
    "                corr_rows.append(corr_row)\n",
    "                corr_row_known = {\n",
    "                    'Participant': participant,\n",
    "                    'Perturb': perturb,\n",
    "                    'Condition': condition,\n",
    "                    'Target': target,\n",
    "                    'Correlation': corr_known\n",
    "                }\n",
    "                corr_rows_known.append(corr_row_known)\n",
    "                corr_row_new = {\n",
    "                    'Participant': participant,\n",
    "                    'Perturb': perturb,\n",
    "                    'Condition': condition,\n",
    "                    'Target': target,\n",
    "                    'Correlation': corr_new\n",
    "                }\n",
    "                corr_rows_new.append(corr_row_new)\n",
    "\n",
    "\n",
    "# Create final long-form dataframes\n",
    "df_corr = pd.DataFrame(corr_rows)\n",
    "df_corr_known = pd.DataFrame(corr_rows_known)\n",
    "df_corr_new = pd.DataFrame(corr_rows_new)\n",
    "\n",
    "# Optional: save\n",
    "df_corr.to_csv('all_correlation_results.csv', index=False)\n",
    "df_corr_known.to_csv('all_correlation_results_known.csv', index=False)\n",
    "df_corr_new.to_csv('all_correlation_results_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50a21533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P_149' 'P_238' 'P_407' 'P_426' 'P_577' 'P_668' 'P_711' 'P_950' 'P7_453'\n",
      " 'P6_820']\n",
      "['P_149' 'P_238' 'P_407' 'P_426' 'P_577' 'P_668' 'P_711' 'P_950' 'P7_453']\n",
      "['P_149' 'P_238' 'P_407' 'P_426' 'P_577' 'P_668' 'P_711' 'P_950' 'P7_453']\n",
      "['P_149' 'P_238' 'P_407' 'P_426' 'P_577' 'P_668' 'P_711' 'P_950' 'P7_453'\n",
      " 'P6_820']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('all_mse_results.csv')\n",
    "# print(df)\n",
    "\n",
    "# now use some groupby wizardry to generate a table for each of the conditions:\n",
    "# first, we want the non perturbed before results\n",
    "df_non_perturbed_before = df[(df['Perturb'] == False) & (df['Condition'] == 'before')]; print(df_non_perturbed_before['Participant'].unique())\n",
    "df_perturbed_after = df[(df['Perturb'] == True) & (df['Condition'] == 'after')]; print(df_perturbed_after['Participant'].unique())\n",
    "df_non_perturbed_after = df[(df['Perturb'] == False) & (df['Condition'] == 'after')]; print(df_non_perturbed_after['Participant'].unique())\n",
    "df_perturbed_before = df[(df['Perturb'] == True) & (df['Condition'] == 'before')]; print(df_perturbed_before['Participant'].unique())\n",
    "\n",
    "# print(df_non_perturbed_after)\n",
    "\n",
    "# now we want to create a new table has columns for each movement and rows for each participant\n",
    "def summaryTable(df):\n",
    "    # Pivot the DataFrame to have movements as columns and participants as rows\n",
    "    df_pivot = df.pivot(index='Participant', columns='Movement', values='MSE')\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "    df_pivot.columns.name = None  # Remove the name of the columns index\n",
    "    df_pivot = df_pivot.rename_axis(None, axis=1)  # Remove the name of the columns index\n",
    "\n",
    "    # Replace participant IDs with their numbers, but only if that participant has data in this table\n",
    "    for i, participant in enumerate(df_pivot['Participant']):\n",
    "        if participant in ptcID:\n",
    "            df_pivot.loc[i, 'Participant'] = ptcID[participant]\n",
    "        else:\n",
    "            df_pivot.loc[i, 'Participant'] = participant\n",
    "\n",
    "    df_pivot.sort_values(by='Participant', inplace=True)\n",
    "\n",
    "    # Calculate mean across all movements\n",
    "    df_pivot['Mean All Movements'] = df_pivot.loc[:, movements].mean(axis=1)\n",
    "    # Calculate mean across known movements\n",
    "    df_pivot['Mean Known Movements'] = df_pivot.loc[:, recordings].mean(axis=1)\n",
    "    # Calculate mean across new movements\n",
    "    df_pivot['Mean New Movements'] = df_pivot.loc[:, test_recordings].mean(axis=1)\n",
    "    \n",
    "    return df_pivot\n",
    "# print(df_non_perturbed_before_pivot)\n",
    "\n",
    "df_non_perturbed_before_pivot = summaryTable(df_non_perturbed_before)\n",
    "df_perturbed_after_pivot = summaryTable(df_perturbed_after)\n",
    "df_non_perturbed_after_pivot = summaryTable(df_non_perturbed_after)\n",
    "df_perturbed_before_pivot = summaryTable(df_perturbed_before)\n",
    "\n",
    "# Print the summary tables\n",
    "# print(\"Non Perturbed Before:\")\n",
    "# print(df_non_perturbed_before_pivot)\n",
    "# print(\"\\nPerturbed After:\")\n",
    "# print(df_perturbed_after_pivot)\n",
    "# print(\"\\nNon Perturbed After:\")\n",
    "# print(df_non_perturbed_after_pivot)\n",
    "# print(\"\\nPerturbed Before:\")\n",
    "# print(df_perturbed_before_pivot)\n",
    "\n",
    "# # convert to latex\n",
    "# print(\"\\nNon Perturbed Before LaTeX:\")  \n",
    "# print(df_non_perturbed_before_pivot.to_latex(index=False, float_format=\"%.3f\", escape=False))\n",
    "# print(\"\\nPerturbed After LaTeX:\")\n",
    "# print(df_perturbed_after_pivot.to_latex(index=False, float_format=\"%.3f\", escape=False))\n",
    "# print(\"\\nNon Perturbed After LaTeX:\")\n",
    "# print(df_non_perturbed_after_pivot.to_latex(index=False, float_format=\"%.3f\", escape=False))\n",
    "# print(\"\\nPerturbed Before LaTeX:\")\n",
    "# print(df_perturbed_before_pivot.to_latex(index=False, float_format=\"%.3f\", escape=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "323eb072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Perturbed Before:\n",
      "   Participant  indexAng    midAng  pinkyAng   ringAng thumbInPlaneAng thumbOutPlaneAng wristFlex Mean Correlation Mean Transformed Correlation\n",
      "0           A1  0.432817  0.783062  0.772695     0.798        0.587512         0.696648  0.834737         0.700782                     0.721464\n",
      "1           A2  0.564108  0.840717  0.876979  0.842683        0.389431         0.605249   0.67636         0.685075                     0.722517\n",
      "2           P1  0.590285  0.871499  0.878547  0.880554         0.32172         0.597532  0.721669         0.694544                     0.742933\n",
      "3           P2  0.562743  0.797293  0.770678  0.769205        0.506427         0.595382   0.78507         0.683828                     0.699969\n",
      "4           P3  0.699111  0.877848   0.87653  0.874538        0.413075         0.547442  0.774866         0.723344                     0.763445\n",
      "5           P4  0.499135  0.783116  0.784181  0.783314        0.397502         0.456353   0.85927         0.651839                     0.688484\n",
      "6           P5  0.835314  0.878553  0.898445  0.883675        0.521434         0.723083  0.790424         0.790133                     0.815191\n",
      "7           P6  0.459817  0.841179  0.877593  0.862477        0.747971          0.66478  0.512801         0.709517                     0.744697\n",
      "8           P7    0.6147  0.892704  0.867108  0.883211        0.444012         0.629438  0.883292         0.744923                     0.788451\n",
      "9           P8  0.432246   0.85224  0.862375  0.859534        0.474993         0.495412  0.815798         0.684657                     0.731582\n",
      "10    Amputees  0.498462   0.81189  0.824837  0.820341        0.488471         0.650948  0.755549         0.692928                     0.721991\n",
      "11      Intact  0.586669  0.849304  0.851932  0.849563        0.478392         0.588678  0.767899         0.710348                     0.749605\n",
      "\n",
      "Perturbed After:\n",
      "   Participant  indexAng    midAng  pinkyAng   ringAng thumbInPlaneAng thumbOutPlaneAng wristFlex Mean Correlation Mean Transformed Correlation\n",
      "0           A1  0.288653  0.688021  0.685186  0.708059        0.145258         0.585577  0.686387          0.54102                      0.56894\n",
      "1           P1  0.400619  0.795519  0.799848  0.805728        0.251529         0.352511  0.515346         0.560157                     0.606081\n",
      "2           P2  0.068798  0.532825    0.5003  0.489473         0.37891          0.43091  0.778693         0.454273                     0.478791\n",
      "3           P3  0.500323  0.711634  0.732627  0.698664        0.346623          0.49532  0.600773         0.583709                     0.598746\n",
      "4           P4  0.262624  0.659925  0.675601  0.670314         0.06761          0.08718   0.77358         0.456691                     0.503533\n",
      "5           P5  0.757501  0.755522  0.791621  0.757424        0.211418         0.569275  0.764273         0.658148                     0.688031\n",
      "6           P6  0.577778  0.825373  0.874384   0.85099        0.716807         0.577354  0.568245          0.71299                     0.739664\n",
      "7           P7  0.337992  0.762591  0.763768  0.740505         0.46957         0.465197  0.858028         0.628236                     0.664855\n",
      "8           P8  0.404392  0.792096  0.790153  0.798069        0.331793         0.352509  0.820994         0.612858                     0.659544\n",
      "9     Amputees  0.288653  0.688021  0.685186  0.708059        0.145258         0.585577  0.686387          0.54102                      0.56894\n",
      "10      Intact  0.413753  0.729436  0.741038  0.726396        0.346783         0.416282  0.709992         0.583383                     0.624345\n",
      "\n",
      "Non Perturbed After:\n",
      "   Participant  indexAng    midAng  pinkyAng   ringAng thumbInPlaneAng thumbOutPlaneAng wristFlex Mean Correlation Mean Transformed Correlation\n",
      "0           A1  0.305402  0.686338  0.682484  0.695123        0.301304         0.571533  0.810675          0.57898                      0.60778\n",
      "1           P1   0.54241  0.804112  0.836191  0.822655        0.141591         0.404575  0.600824         0.593194                     0.644192\n",
      "2           P2  0.399018  0.753923   0.73513  0.725065        0.502078         0.690343  0.696468         0.643146                     0.657891\n",
      "3           P3  0.299523  0.607008  0.602688    0.5921        0.442021         0.623717  0.523278         0.527191                     0.534816\n",
      "4           P4  0.374455  0.735253  0.719634  0.713953        0.130718          0.37193  0.853884         0.557118                     0.606918\n",
      "5           P5  0.761676  0.759156  0.815609   0.76754        0.094485         0.697721  0.798953         0.670734                     0.709669\n",
      "6           P6  0.588778  0.847831  0.898979  0.879611        0.744057         0.480232  0.610498         0.721426                     0.759039\n",
      "7           P7  0.494904  0.787538  0.735899  0.763833        0.322805         0.506022  0.917457         0.646923                     0.696194\n",
      "8           P8  0.360445  0.869481  0.885534     0.879        0.419244         0.397854  0.788722         0.657183                     0.724302\n",
      "9     Amputees  0.305402  0.686338  0.682484  0.695123        0.301304         0.571533  0.810675          0.57898                      0.60778\n",
      "10      Intact  0.477651  0.770538  0.778708   0.76797        0.349625         0.521549   0.72376         0.627114                     0.671809\n",
      "\n",
      "Perturbed Before:\n",
      "   Participant  indexAng    midAng  pinkyAng   ringAng thumbInPlaneAng thumbOutPlaneAng wristFlex Mean Correlation Mean Transformed Correlation\n",
      "0           A1  0.368368  0.199425  0.236625  0.244354        0.428947         0.170824  0.454037         0.300369                     0.304351\n",
      "1           A2  0.234456  0.321488  0.262962   0.28779         0.07638         0.167905  0.592528         0.277644                     0.286762\n",
      "2           P1   0.41618  0.777981  0.793946  0.789565        0.139079         0.303925  0.168668         0.484192                     0.543092\n",
      "3           P2 -0.078723 -0.315541 -0.332196 -0.357672        0.259957         0.213349  0.427423        -0.026201                    -0.026509\n",
      "4           P3 -0.087157    0.0859  0.125017  0.088012       -0.092322         0.325498   0.48818         0.133304                     0.140705\n",
      "5           P4  0.038606 -0.056521 -0.080779 -0.111472        0.273478         0.075107  0.623588         0.108858                     0.124476\n",
      "6           P5  0.440991  0.541472  0.503553  0.515074        0.049604         0.439233  0.594594         0.440646                     0.451835\n",
      "7           P6 -0.058643  -0.16171 -0.182284 -0.132796        0.009181         0.600358  0.303516         0.053946                     0.067965\n",
      "8           P7 -0.069219  0.114553  0.125144  0.094841       -0.171631         0.211671   0.68562         0.141568                     0.162528\n",
      "9           P8  0.063725  0.173913  0.224329  0.251391        0.423045         0.078275  0.704567         0.274178                     0.295329\n",
      "10    Amputees  0.301412  0.260456  0.249793  0.266072        0.252664         0.169364  0.523282         0.289006                     0.295582\n",
      "11      Intact   0.08322  0.145006  0.147091  0.142118        0.111299         0.280927  0.499519         0.201311                     0.229849\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('all_correlation_results_known.csv')\n",
    "# print(df)\n",
    "\n",
    "# now use some groupby wizardry to generate a table for each of the conditions:\n",
    "# first, we want the non perturbed before results\n",
    "df_non_perturbed_before = df[(df['Perturb'] == False) & (df['Condition'] == 'before')]\n",
    "df_perturbed_after = df[(df['Perturb'] == True) & (df['Condition'] == 'after')]\n",
    "df_non_perturbed_after = df[(df['Perturb'] == False) & (df['Condition'] == 'after')]\n",
    "df_perturbed_before = df[(df['Perturb'] == True) & (df['Condition'] == 'before')]\n",
    "\n",
    "# now we want to create a new table has columns for each movement and rows for each participant\n",
    "def summaryTable(df):\n",
    "    # Pivot the DataFrame to have movements as columns and participants as rows\n",
    "    df_pivot = df.pivot(index='Participant', columns='Target', values='Correlation')\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "    df_pivot.columns.name = None  # Remove the name of the columns index\n",
    "    df_pivot = df_pivot.rename_axis(None, axis=1)  # Remove the name of the columns index\n",
    "\n",
    "    # Replace participant IDs with short names\n",
    "    # df_pivot['Participant'] = df_pivot['Participant'].replace(ptcID)\n",
    "    for i, participant in enumerate(df_pivot['Participant']):\n",
    "        if participant in ptcID:\n",
    "            df_pivot.loc[i, 'Participant'] = ptcID[participant]\n",
    "        else:\n",
    "            df_pivot.loc[i, 'Participant'] = participant\n",
    "\n",
    "    df_pivot.sort_values(by='Participant', inplace=True)\n",
    "\n",
    "    # do a fisher transformation on the correlations\n",
    "    transformed_corr = np.arctanh(df_pivot.loc[:, targets])\n",
    "\n",
    "    # have to do this by cohort\n",
    "    # mean_transformed_corr_amp = transformed_corr.loc[df_pivot['Participant'].str.startswith('A')].mean(axis=1)\n",
    "    # mean_transformed_corr_intact = transformed_corr.loc[df_pivot['Participant'].str.startswith('P')].mean(axis=1)\n",
    "\n",
    "    mean_transformed_corr = transformed_corr.mean(axis=1)\n",
    "    # apply the inverse fisher transformation to get back to correlation space\n",
    "\n",
    "    # Calculate mean across all movements\n",
    "    df_pivot['Mean Correlation'] = df_pivot.loc[:, targets].mean(axis=1)\n",
    "    df_pivot['Mean Transformed Correlation'] = np.tanh(mean_transformed_corr)\n",
    "\n",
    "    # add an extra row that is the mean across all participants\n",
    "    mean_row = df_pivot.loc[df_pivot['Participant'].str.startswith('A'), targets].mean()\n",
    "    mean_transform = transformed_corr.loc[df_pivot['Participant'].str.startswith('A')].mean().mean()\n",
    "    mean_row['Participant'] = 'Amputees'\n",
    "    mean_row['Mean Correlation'] = mean_row.loc[targets].mean()\n",
    "    mean_row['Mean Transformed Correlation'] = np.tanh(mean_transform)\n",
    "\n",
    "    mean_row_ = df_pivot.loc[df_pivot['Participant'].str.startswith('P'), targets].mean()\n",
    "    mean_transform_ = transformed_corr.loc[df_pivot['Participant'].str.startswith('P')].mean().mean()\n",
    "    mean_row_['Participant'] = 'Intact'\n",
    "    mean_row_['Mean Correlation'] = mean_row_.loc[targets].mean()\n",
    "    mean_row_['Mean Transformed Correlation'] = np.tanh(mean_transform_)\n",
    "\n",
    "    df_pivot = pd.concat([df_pivot, mean_row.to_frame().T, mean_row_.to_frame().T], ignore_index=True)\n",
    "\n",
    "    return df_pivot\n",
    "# print(df_non_perturbed_before_pivot)\n",
    "\n",
    "df_non_perturbed_before_pivot = summaryTable(df_non_perturbed_before)\n",
    "df_perturbed_after_pivot = summaryTable(df_perturbed_after)\n",
    "df_non_perturbed_after_pivot = summaryTable(df_non_perturbed_after)\n",
    "df_perturbed_before_pivot = summaryTable(df_perturbed_before)\n",
    "\n",
    "# Print the summary tables\n",
    "print(\"Non Perturbed Before:\")\n",
    "print(df_non_perturbed_before_pivot)\n",
    "print(\"\\nPerturbed After:\")\n",
    "print(df_perturbed_after_pivot)\n",
    "print(\"\\nNon Perturbed After:\")\n",
    "print(df_non_perturbed_after_pivot)\n",
    "print(\"\\nPerturbed Before:\")\n",
    "print(df_perturbed_before_pivot)\n",
    "\n",
    "# convert to latex\n",
    "# print(\"\\nNon Perturbed Before LaTeX:\")  \n",
    "# print(df_non_perturbed_before_pivot.to_latex(index=False, float_format=\"%.3f\", escape=False))\n",
    "# print(\"\\nPerturbed After LaTeX:\")\n",
    "# print(df_perturbed_after_pivot.to_latex(index=False, float_format=\"%.3f\", escape=False))\n",
    "# print(\"\\nNon Perturbed After LaTeX:\")\n",
    "# print(df_non_perturbed_after_pivot.to_latex(index=False, float_format=\"%.3f\", escape=False))\n",
    "# print(\"\\nPerturbed Before LaTeX:\")\n",
    "# print(df_perturbed_before_pivot.to_latex(index=False, float_format=\"%.3f\", escape=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "50fac917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "    \\caption{Known Movements Correlation Results (initial training)}\n",
      "    \\label{tab:corr_known_initial}\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{%\n",
      "    \\begin{tabular}{|l|ccccccccc|}\n",
      "        \\hline\n",
      "        Participant & indexAng & midAng & pinkyAng & ringAng & thumbInPlaneAng & thumbOutPlaneAng & wristFlex & Mean Correlation & Mean Transformed Correlation \\\\\n",
      "        \\hline\n",
      "        A1 & 0.433 & 0.783 & 0.773 & 0.798 & 0.588 & 0.697 & 0.835 & 0.701 & 0.721 \\\\\n",
      "A2 & 0.564 & 0.841 & 0.877 & 0.843 & 0.389 & 0.605 & 0.676 & 0.685 & 0.723 \\\\\n",
      "P1 & 0.590 & 0.871 & 0.879 & 0.881 & 0.322 & 0.598 & 0.722 & 0.695 & 0.743 \\\\\n",
      "P2 & 0.563 & 0.797 & 0.771 & 0.769 & 0.506 & 0.595 & 0.785 & 0.684 & 0.700 \\\\\n",
      "P3 & 0.699 & 0.878 & 0.877 & 0.875 & 0.413 & 0.547 & 0.775 & 0.723 & 0.763 \\\\\n",
      "P4 & 0.499 & 0.783 & 0.784 & 0.783 & 0.398 & 0.456 & 0.859 & 0.652 & 0.688 \\\\\n",
      "P5 & 0.835 & 0.879 & 0.898 & 0.884 & 0.521 & 0.723 & 0.790 & 0.790 & 0.815 \\\\\n",
      "P6 & 0.460 & 0.841 & 0.878 & 0.862 & 0.748 & 0.665 & 0.513 & 0.710 & 0.745 \\\\\n",
      "P7 & 0.615 & 0.893 & 0.867 & 0.883 & 0.444 & 0.629 & 0.883 & 0.745 & 0.788 \\\\\n",
      "P8 & 0.432 & 0.852 & 0.862 & 0.860 & 0.475 & 0.495 & 0.816 & 0.685 & 0.732 \\\\\n",
      "Amputees & 0.498 & 0.812 & 0.825 & 0.820 & 0.488 & 0.651 & 0.756 & 0.693 & 0.722 \\\\\n",
      "Intact & 0.587 & 0.849 & 0.852 & 0.850 & 0.478 & 0.589 & 0.768 & 0.710 & 0.750 \\\\\n",
      "        \\hline\n",
      "    \\end{tabular}\n",
      "    }\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "\\begin{table}[ht]\n",
      "    \\caption{Known Movements Correlation Results (after online training)}\n",
      "    \\label{tab:corr_known_online}\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{%\n",
      "    \\begin{tabular}{|l|ccccccccc|}\n",
      "        \\hline\n",
      "        Participant & indexAng & midAng & pinkyAng & ringAng & thumbInPlaneAng & thumbOutPlaneAng & wristFlex & Mean Correlation & Mean Transformed Correlation \\\\\n",
      "        \\hline\n",
      "        A1 & 0.289 & 0.688 & 0.685 & 0.708 & 0.145 & 0.586 & 0.686 & 0.541 & 0.569 \\\\\n",
      "P1 & 0.401 & 0.796 & 0.800 & 0.806 & 0.252 & 0.353 & 0.515 & 0.560 & 0.606 \\\\\n",
      "P2 & 0.069 & 0.533 & 0.500 & 0.489 & 0.379 & 0.431 & 0.779 & 0.454 & 0.479 \\\\\n",
      "P3 & 0.500 & 0.712 & 0.733 & 0.699 & 0.347 & 0.495 & 0.601 & 0.584 & 0.599 \\\\\n",
      "P4 & 0.263 & 0.660 & 0.676 & 0.670 & 0.068 & 0.087 & 0.774 & 0.457 & 0.504 \\\\\n",
      "P5 & 0.758 & 0.756 & 0.792 & 0.757 & 0.211 & 0.569 & 0.764 & 0.658 & 0.688 \\\\\n",
      "P6 & 0.578 & 0.825 & 0.874 & 0.851 & 0.717 & 0.577 & 0.568 & 0.713 & 0.740 \\\\\n",
      "P7 & 0.338 & 0.763 & 0.764 & 0.741 & 0.470 & 0.465 & 0.858 & 0.628 & 0.665 \\\\\n",
      "P8 & 0.404 & 0.792 & 0.790 & 0.798 & 0.332 & 0.353 & 0.821 & 0.613 & 0.660 \\\\\n",
      "Amputees & 0.289 & 0.688 & 0.685 & 0.708 & 0.145 & 0.586 & 0.686 & 0.541 & 0.569 \\\\\n",
      "Intact & 0.414 & 0.729 & 0.741 & 0.726 & 0.347 & 0.416 & 0.710 & 0.583 & 0.624 \\\\\n",
      "        \\hline\n",
      "    \\end{tabular}\n",
      "    }\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "\\begin{table}[ht]\n",
      "    \\caption{Known Movements Correlation Results (before online training, perturbed input)}\n",
      "    \\label{tab:corr_known_after_perturbed}\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{%\n",
      "    \\begin{tabular}{|l|ccccccccc|}\n",
      "        \\hline\n",
      "        Participant & indexAng & midAng & pinkyAng & ringAng & thumbInPlaneAng & thumbOutPlaneAng & wristFlex & Mean Correlation & Mean Transformed Correlation \\\\\n",
      "        \\hline\n",
      "        A1 & 0.368 & 0.199 & 0.237 & 0.244 & 0.429 & 0.171 & 0.454 & 0.300 & 0.304 \\\\\n",
      "A2 & 0.234 & 0.321 & 0.263 & 0.288 & 0.076 & 0.168 & 0.593 & 0.278 & 0.287 \\\\\n",
      "P1 & 0.416 & 0.778 & 0.794 & 0.790 & 0.139 & 0.304 & 0.169 & 0.484 & 0.543 \\\\\n",
      "P2 & -0.079 & -0.316 & -0.332 & -0.358 & 0.260 & 0.213 & 0.427 & -0.026 & -0.027 \\\\\n",
      "P3 & -0.087 & 0.086 & 0.125 & 0.088 & -0.092 & 0.325 & 0.488 & 0.133 & 0.141 \\\\\n",
      "P4 & 0.039 & -0.057 & -0.081 & -0.111 & 0.273 & 0.075 & 0.624 & 0.109 & 0.124 \\\\\n",
      "P5 & 0.441 & 0.541 & 0.504 & 0.515 & 0.050 & 0.439 & 0.595 & 0.441 & 0.452 \\\\\n",
      "P6 & -0.059 & -0.162 & -0.182 & -0.133 & 0.009 & 0.600 & 0.304 & 0.054 & 0.068 \\\\\n",
      "P7 & -0.069 & 0.115 & 0.125 & 0.095 & -0.172 & 0.212 & 0.686 & 0.142 & 0.163 \\\\\n",
      "P8 & 0.064 & 0.174 & 0.224 & 0.251 & 0.423 & 0.078 & 0.705 & 0.274 & 0.295 \\\\\n",
      "Amputees & 0.301 & 0.260 & 0.250 & 0.266 & 0.253 & 0.169 & 0.523 & 0.289 & 0.296 \\\\\n",
      "Intact & 0.083 & 0.145 & 0.147 & 0.142 & 0.111 & 0.281 & 0.500 & 0.201 & 0.230 \\\\\n",
      "        \\hline\n",
      "    \\end{tabular}\n",
      "    }\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "\\begin{table}[ht]\n",
      "    \\caption{Known Movements Correlation Results (after online training, perturbed input)}\n",
      "    \\label{tab:corr_known_before_perturbed}\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{%\n",
      "    \\begin{tabular}{|l|ccccccccc|}\n",
      "        \\hline\n",
      "        Participant & indexAng & midAng & pinkyAng & ringAng & thumbInPlaneAng & thumbOutPlaneAng & wristFlex & Mean Correlation & Mean Transformed Correlation \\\\\n",
      "        \\hline\n",
      "        A1 & 0.305 & 0.686 & 0.682 & 0.695 & 0.301 & 0.572 & 0.811 & 0.579 & 0.608 \\\\\n",
      "P1 & 0.542 & 0.804 & 0.836 & 0.823 & 0.142 & 0.405 & 0.601 & 0.593 & 0.644 \\\\\n",
      "P2 & 0.399 & 0.754 & 0.735 & 0.725 & 0.502 & 0.690 & 0.696 & 0.643 & 0.658 \\\\\n",
      "P3 & 0.300 & 0.607 & 0.603 & 0.592 & 0.442 & 0.624 & 0.523 & 0.527 & 0.535 \\\\\n",
      "P4 & 0.374 & 0.735 & 0.720 & 0.714 & 0.131 & 0.372 & 0.854 & 0.557 & 0.607 \\\\\n",
      "P5 & 0.762 & 0.759 & 0.816 & 0.768 & 0.094 & 0.698 & 0.799 & 0.671 & 0.710 \\\\\n",
      "P6 & 0.589 & 0.848 & 0.899 & 0.880 & 0.744 & 0.480 & 0.610 & 0.721 & 0.759 \\\\\n",
      "P7 & 0.495 & 0.788 & 0.736 & 0.764 & 0.323 & 0.506 & 0.917 & 0.647 & 0.696 \\\\\n",
      "P8 & 0.360 & 0.869 & 0.886 & 0.879 & 0.419 & 0.398 & 0.789 & 0.657 & 0.724 \\\\\n",
      "Amputees & 0.305 & 0.686 & 0.682 & 0.695 & 0.301 & 0.572 & 0.811 & 0.579 & 0.608 \\\\\n",
      "Intact & 0.478 & 0.771 & 0.779 & 0.768 & 0.350 & 0.522 & 0.724 & 0.627 & 0.672 \\\\\n",
      "        \\hline\n",
      "    \\end{tabular}\n",
      "    }\n",
      "\\end{table}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def df_to_latex(df, caption, label):\n",
    "    col_names = list(df.columns)\n",
    "    # col_names.replace('Mean Correlation', 'Mean Corr.')\n",
    "    # col_names.replace('Mean Transformed Correlation', 'Mean Transformed Corr.')\n",
    "    # Create LaTeX column format string (e.g., \"|l|ccc|\")\n",
    "    col_format = \"|l|\" + \"c\" * (len(col_names) - 1) + \"|\"\n",
    "\n",
    "    # Create header row\n",
    "    header_row = \" & \".join(col_names) + \" \\\\\\\\\"\n",
    "\n",
    "    # we want to go in ascending order of participants\n",
    "    # df = df.sort_values(by='Participant')\n",
    "\n",
    "    # Create data rows\n",
    "    data_rows = \"\\n\".join(\n",
    "        \" & \".join([str(row[0])] + [f\"{val:.3f}\" for val in row[1:]]) + \" \\\\\\\\\"\n",
    "        for index, row in df.iterrows()\n",
    "    )\n",
    "\n",
    "    latex_str = f\"\"\"\\\\begin{{table}}[ht]\n",
    "    \\\\caption{{{caption}}}\n",
    "    \\\\label{{{label}}}\n",
    "    \\\\centering\n",
    "    \\\\resizebox{{\\\\textwidth}}{{!}}{{%\n",
    "    \\\\begin{{tabular}}{{{col_format}}}\n",
    "        \\\\hline\n",
    "        {header_row}\n",
    "        \\\\hline\n",
    "        {data_rows}\n",
    "        \\\\hline\n",
    "    \\\\end{{tabular}}\n",
    "    }}\n",
    "\\\\end{{table}}\"\"\"\n",
    "\n",
    "    return latex_str\n",
    "\n",
    "\n",
    "def df_to_latex_split(df, caption, label):\n",
    "    # Split main movement columns from mean summary columns\n",
    "    df = df.sort_values(by='Participant')\n",
    "    mean_cols = [col for col in df.columns if 'Mean' in col]\n",
    "\n",
    "    # Format the main table\n",
    "    header_main = \" & \".join(['\\\\textbf{Participant}'] + movements) + \" \\\\\\\\\"\n",
    "    rows_main = \"\\n\".join(\n",
    "        \" & \".join([str(row['Participant'])] + [f\"{row[col]:.3f}\" for col in movements]) + \" \\\\\\\\\"\n",
    "        for _, row in df.iterrows()\n",
    "    )\n",
    "\n",
    "    # Format the smaller table\n",
    "    header_summary = \" & \".join(['\\\\textbf{Participant}'] + [f\"\\\\textbf{{{col}}}\" for col in mean_cols]) + \" \\\\\\\\\"\n",
    "    rows_summary = \"\\n\".join(\n",
    "        \" & \".join([str(row['Participant'])] + [f\"{row[col]:.3f}\" for col in mean_cols]) + \" \\\\\\\\\"\n",
    "        for _, row in df.iterrows()\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "\\\\begin{{table}}[ht!]\n",
    "    \\\\caption{{{caption}}}\n",
    "    \\\\label{{{label}}}\n",
    "    \\\\centering\n",
    "    \\\\resizebox{{\\\\textwidth}}{{!}}{{%\n",
    "    \\\\begin{{tabular}}{{|l|{'c' * len(movements)}|}}\n",
    "        \\\\hline\n",
    "        {header_main}\n",
    "        \\\\hline\n",
    "        {rows_main}\n",
    "        \\\\hline\n",
    "    \\\\end{{tabular}}\n",
    "    }}\\\\\\\\[1em]\n",
    "    \\\\begin{{scriptsize}}\n",
    "    \\\\begin{{tabular}}{{|l|{'c' * len(mean_cols)}|}}\n",
    "        \\\\hline\n",
    "        {header_summary}\n",
    "        \\\\hline\n",
    "        {rows_summary}\n",
    "        \\\\hline\n",
    "    \\\\end{{tabular}}\n",
    "    \\\\end{{scriptsize}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "# MSE\n",
    "# dfs = [df_non_perturbed_before_pivot, df_perturbed_after_pivot, df_perturbed_before_pivot, df_non_perturbed_after_pivot]\n",
    "# captions = [f'MSE for each movement ({cap})' for cap in ['initial training', 'after online training', 'before online training, perturbed input', 'after online training, perturbed input']]\n",
    "# labels = [f'tab:mse_{label}' for label in ['initial', 'online', 'after_perturbed', 'before_perturbed']]\n",
    "\n",
    "# Correlation\n",
    "dfs = [df_non_perturbed_before_pivot, df_perturbed_after_pivot, df_perturbed_before_pivot, df_non_perturbed_after_pivot]\n",
    "captions = [f'Known Movements Correlation Results ({cap})' for cap in ['initial training', 'after online training', 'before online training, perturbed input', 'after online training, perturbed input']]\n",
    "labels = [f'tab:corr_known_{label}' for label in ['initial', 'online', 'after_perturbed', 'before_perturbed']]\n",
    "\n",
    "for df, caption, label in zip(dfs, captions, labels):\n",
    "    # latex_str = df_to_latex_split(df, caption, label)\n",
    "    latex_str = df_to_latex(df, caption, label)\n",
    "    print(latex_str)\n",
    "    print(\"\\n\")  # Add a newline for better readability between tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Test Group Subset  Wilcoxon Statistic   p-value\n",
      "0          Online Training    ALL                12.0  0.250000\n",
      "1          Online Training  KNOWN                 3.0  0.019531\n",
      "2          Online Training    NEW                 0.0  0.003906\n",
      "3          Perturbed Study    ALL                 0.0  0.003906\n",
      "4          Perturbed Study  KNOWN                 0.0  0.003906\n",
      "5          Perturbed Study    NEW                 0.0  0.003906\n",
      "6         Overall Learning    ALL                17.0  0.570312\n",
      "7         Overall Learning  KNOWN                 0.0  0.003906\n",
      "8         Overall Learning    NEW                 0.0  0.003906\n",
      "9   Perturbation Breakdown    ALL                 0.0  0.003906\n",
      "10  Perturbation Breakdown  KNOWN                 0.0  0.003906\n",
      "11  Perturbation Breakdown    NEW                 2.0  0.011719\n"
     ]
    }
   ],
   "source": [
    "# we also want to perform some statistical tests to compare the MSE between conditions\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# we want to perfrom these on the means between different conditions \n",
    "def perform_wilcoxon_test(df1, df2):\n",
    "    # Perform Wilcoxon signed-rank test\n",
    "    stat, p_value = wilcoxon(df1, df2)\n",
    "    return stat, p_value\n",
    "\n",
    "# Perform all tests and collect output\n",
    "results = {}\n",
    "\n",
    "# Pure online training (non-perturbed, before vs after)\n",
    "results['Online Training - ALL'] = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean All Movements'], df_non_perturbed_after_pivot['Mean All Movements'])\n",
    "results['Online Training - KNOWN'] = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean Known Movements'], df_non_perturbed_after_pivot['Mean Known Movements'])\n",
    "results['Online Training - NEW'] = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean New Movements'], df_non_perturbed_after_pivot['Mean New Movements'])\n",
    "\n",
    "# Online learning, perturbation study (perturbed before vs after)\n",
    "results['Perturbed Study - ALL'] = perform_wilcoxon_test(df_perturbed_before_pivot['Mean All Movements'], df_perturbed_after_pivot['Mean All Movements'])\n",
    "results['Perturbed Study - KNOWN'] = perform_wilcoxon_test(df_perturbed_before_pivot['Mean Known Movements'], df_perturbed_after_pivot['Mean Known Movements'])\n",
    "results['Perturbed Study - NEW'] = perform_wilcoxon_test(df_perturbed_before_pivot['Mean New Movements'], df_perturbed_after_pivot['Mean New Movements'])\n",
    "\n",
    "# Overall learning: pre-online vs post-perturbed\n",
    "results['Overall Learning - ALL'] = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean All Movements'], df_perturbed_after_pivot['Mean All Movements'])\n",
    "results['Overall Learning - KNOWN'] = perform_wilcoxon_test(df_non_perturbed_after_pivot['Mean Known Movements'], df_perturbed_before_pivot['Mean Known Movements'])\n",
    "results['Overall Learning - NEW'] = perform_wilcoxon_test(df_perturbed_after_pivot['Mean New Movements'], df_non_perturbed_before_pivot['Mean New Movements'])\n",
    "\n",
    "# Perturbation breakdown: non-perturbed before vs perturbed before\n",
    "results['Perturbation Breakdown - ALL'] = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean All Movements'], df_perturbed_before_pivot['Mean All Movements'])\n",
    "results['Perturbation Breakdown - KNOWN'] = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean Known Movements'], df_perturbed_before_pivot['Mean Known Movements'])\n",
    "results['Perturbation Breakdown - NEW'] = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean New Movements'], df_perturbed_before_pivot['Mean New Movements'])\n",
    "\n",
    "#  Build a DataFrame from the Wilcoxon results\n",
    "summary_rows = []\n",
    "for label, (stat, p_val) in results.items():\n",
    "    group, metric = label.split(\" - \")\n",
    "    summary_rows.append({\n",
    "        \"Test Group\": group,\n",
    "        \"Subset\": metric,\n",
    "        \"Wilcoxon Statistic\": stat,\n",
    "        \"p-value\": p_val\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Sort by logical groupings\n",
    "df_stats['Group Order'] = df_stats['Test Group'].map({\n",
    "    'Online Training': 0,\n",
    "    'Perturbed Study': 1,\n",
    "    'Overall Learning': 2,\n",
    "    'Perturbation Breakdown': 3\n",
    "})\n",
    "df_stats['Subset Order'] = df_stats['Subset'].map({'ALL': 0, 'KNOWN': 1, 'NEW': 2})\n",
    "df_stats.sort_values(by=['Group Order', 'Subset Order'], inplace=True)\n",
    "df_stats.drop(columns=['Group Order', 'Subset Order'], inplace=True)\n",
    "print(df_stats)\n",
    "\n",
    "# # pure online training for new movements\n",
    "# stat, p_value = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean All Movements'], df_non_perturbed_after_pivot['Mean All Movements'])\n",
    "# print(f\"Wilcoxon tests for online training:\\n\\tALL  : Statistic={stat}, p-value={p_value}\")\n",
    "# stat, p_value = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean Known Movements'], df_non_perturbed_after_pivot['Mean Known Movements'])\n",
    "# print(f\"\\tKNOWN: Statistic={stat}, p-value={p_value}\")\n",
    "# stat, p_value = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean New Movements'], df_non_perturbed_after_pivot['Mean New Movements'])\n",
    "# print(f\"\\tNEW  : Statistic={stat}, p-value={p_value}\")\n",
    "\n",
    "# # online learning, perturbation study\n",
    "# stat, p_value = perform_wilcoxon_test(df_perturbed_after_pivot['Mean All Movements'], df_perturbed_before_pivot['Mean All Movements'])\n",
    "# print(f\"\\nWilcoxon tests for online learning, perturbation:\\n\\tALL  : Statistic={stat}, p-value={p_value}\")\n",
    "# stat, p_value = perform_wilcoxon_test(df_perturbed_after_pivot['Mean Known Movements'], df_perturbed_before_pivot['Mean Known Movements'])\n",
    "# print(f\"\\tKNOWN: Statistic={stat}, p-value={p_value}\")\n",
    "# stat, p_value = perform_wilcoxon_test(df_perturbed_after_pivot['Mean New Movements'], df_perturbed_before_pivot['Mean New Movements'])\n",
    "# print(f\"\\tNEW  : Statistic={stat}, p-value={p_value}\")\n",
    "\n",
    "# # for all learning\n",
    "# stat, p_value = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean All Movements'], df_perturbed_after_pivot['Mean All Movements'])\n",
    "# print(f\"\\nWilcoxon test for overall learning:\\n\\tALL  : Statistic={stat}, p-value={p_value}\")\n",
    "# stat, p_value = perform_wilcoxon_test(df_non_perturbed_after_pivot['Mean Known Movements'], df_perturbed_before_pivot['Mean Known Movements'])\n",
    "# print(f\"\\tKNOWN: Statistic={stat}, p-value={p_value}\")\n",
    "# stat, p_value = perform_wilcoxon_test(df_perturbed_after_pivot['Mean New Movements'], df_non_perturbed_before_pivot['Mean New Movements'])\n",
    "# print(f\"\\tNEW  : Statistic={stat}, p-value={p_value}\")\n",
    "\n",
    "# # validate that perturbation breaks down the MSE\n",
    "# stat, p_value = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean All Movements'], df_perturbed_before_pivot['Mean All Movements'])\n",
    "# print(f\"\\nWilcoxon test for perturbation breakdown:\\n\\tALL  : Statistic={stat}, p-value={p_value}\")\n",
    "# stat, p_value = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean Known Movements'], df_perturbed_before_pivot['Mean Known Movements'])\n",
    "# print(f\"\\tKNOWN: Statistic={stat}, p-value={p_value}\")\n",
    "# stat, p_value = perform_wilcoxon_test(df_non_perturbed_before_pivot['Mean New Movements'], df_perturbed_before_pivot['Mean New Movements'])\n",
    "# print(f\"\\tNEW  : Statistic={stat}, p-value={p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "556db810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Test Group Subset  Effect Size (r)\n",
      "0          Online Training    ALL         0.466667\n",
      "1          Online Training  KNOWN        -0.866667\n",
      "2          Online Training    NEW         1.000000\n",
      "3          Perturbed Study    ALL         1.000000\n",
      "4          Perturbed Study  KNOWN         1.000000\n",
      "5          Perturbed Study    NEW         1.000000\n",
      "6         Overall Learning    ALL         0.244444\n",
      "7         Overall Learning  KNOWN        -1.000000\n",
      "8         Overall Learning    NEW        -1.000000\n",
      "9   Perturbation Breakdown    ALL        -1.000000\n",
      "10  Perturbation Breakdown  KNOWN        -1.000000\n",
      "11  Perturbation Breakdown    NEW        -0.911111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Manual rank-biserial effect size computation for paired samples\n",
    "def rank_biserial(pre, post):\n",
    "    diffs = np.array(pre) - np.array(post)\n",
    "    non_zero = diffs != 0\n",
    "    diffs = diffs[non_zero]\n",
    "    signs = np.sign(diffs)\n",
    "    ranks = rankdata(abs(diffs))\n",
    "    effect_size = np.sum(signs * ranks) / np.sum(ranks)\n",
    "    return effect_size\n",
    "\n",
    "# Recompute all effect sizes manually\n",
    "effect_sizes_manual = {}\n",
    "\n",
    "# Pure online training (non-perturbed, before vs after)\n",
    "effect_sizes_manual['Online Training - ALL'] = rank_biserial(df_non_perturbed_before_pivot['Mean All Movements'], df_non_perturbed_after_pivot['Mean All Movements'])\n",
    "effect_sizes_manual['Online Training - KNOWN'] = rank_biserial(df_non_perturbed_before_pivot['Mean Known Movements'], df_non_perturbed_after_pivot['Mean Known Movements'])\n",
    "effect_sizes_manual['Online Training - NEW'] = rank_biserial(df_non_perturbed_before_pivot['Mean New Movements'], df_non_perturbed_after_pivot['Mean New Movements'])\n",
    "\n",
    "# Online learning, perturbation study (perturbed before vs after)\n",
    "effect_sizes_manual['Perturbed Study - ALL'] = rank_biserial(df_perturbed_before_pivot['Mean All Movements'], df_perturbed_after_pivot['Mean All Movements'])\n",
    "effect_sizes_manual['Perturbed Study - KNOWN'] = rank_biserial(df_perturbed_before_pivot['Mean Known Movements'], df_perturbed_after_pivot['Mean Known Movements'])\n",
    "effect_sizes_manual['Perturbed Study - NEW'] = rank_biserial(df_perturbed_before_pivot['Mean New Movements'], df_perturbed_after_pivot['Mean New Movements'])\n",
    "\n",
    "# Overall learning: pre-online vs post-perturbed\n",
    "effect_sizes_manual['Overall Learning - ALL'] = rank_biserial(df_non_perturbed_before_pivot['Mean All Movements'], df_perturbed_after_pivot['Mean All Movements'])\n",
    "effect_sizes_manual['Overall Learning - KNOWN'] = rank_biserial(df_non_perturbed_after_pivot['Mean Known Movements'], df_perturbed_before_pivot['Mean Known Movements'])\n",
    "effect_sizes_manual['Overall Learning - NEW'] = rank_biserial(df_perturbed_after_pivot['Mean New Movements'], df_non_perturbed_before_pivot['Mean New Movements'])\n",
    "\n",
    "# Perturbation breakdown: non-perturbed before vs perturbed before\n",
    "effect_sizes_manual['Perturbation Breakdown - ALL'] = rank_biserial(df_non_perturbed_before_pivot['Mean All Movements'], df_perturbed_before_pivot['Mean All Movements'])\n",
    "effect_sizes_manual['Perturbation Breakdown - KNOWN'] = rank_biserial(df_non_perturbed_before_pivot['Mean Known Movements'], df_perturbed_before_pivot['Mean Known Movements'])\n",
    "effect_sizes_manual['Perturbation Breakdown - NEW'] = rank_biserial(df_non_perturbed_before_pivot['Mean New Movements'], df_perturbed_before_pivot['Mean New Movements'])\n",
    "\n",
    "# Build DataFrame\n",
    "df_effects_manual = pd.DataFrame([\n",
    "    {\"Test Group\": label.split(\" - \")[0], \"Subset\": label.split(\" - \")[1], \"Effect Size (r)\": r}\n",
    "    for label, r in effect_sizes_manual.items()\n",
    "])\n",
    "\n",
    "# Sort like before\n",
    "df_effects_manual['Group Order'] = df_effects_manual['Test Group'].map({\n",
    "    'Online Training': 0,\n",
    "    'Perturbed Study': 1,\n",
    "    'Overall Learning': 2,\n",
    "    'Perturbation Breakdown': 3\n",
    "})\n",
    "df_effects_manual['Subset Order'] = df_effects_manual['Subset'].map({'ALL': 0, 'KNOWN': 1, 'NEW': 2})\n",
    "df_effects_manual.sort_values(by=['Group Order', 'Subset Order'], inplace=True)\n",
    "df_effects_manual.drop(columns=['Group Order', 'Subset Order'], inplace=True)\n",
    "\n",
    "print(df_effects_manual)\n",
    "\n",
    "# tools.display_dataframe_to_user(name=\"Wilcoxon Effect Sizes (Manual)\", dataframe=df_effects_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e952a315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Wilcoxon test results with rank-biserial effect sizes for MSE comparisons across conditions.}\n",
      "\\label{tab:wilcoxon_full_results}\n",
      "\\begin{tabular}{llrrr}\n",
      "\\toprule\n",
      "Test Group & Subset & Wilcoxon Statistic & p-value & Effect Size (r) \\\\\n",
      "\\midrule\n",
      "Online Training & ALL & 12.00000 & 0.25000 & 0.46667 \\\\\n",
      "Online Training & KNOWN & 3.00000 & 0.01953 & -0.86667 \\\\\n",
      "Online Training & NEW & 0.00000 & 0.00391 & 1.00000 \\\\\n",
      "Perturbed Study & ALL & 0.00000 & 0.00391 & 1.00000 \\\\\n",
      "Perturbed Study & KNOWN & 0.00000 & 0.00391 & 1.00000 \\\\\n",
      "Perturbed Study & NEW & 0.00000 & 0.00391 & 1.00000 \\\\\n",
      "Overall Learning & ALL & 17.00000 & 0.57031 & 0.24444 \\\\\n",
      "Overall Learning & KNOWN & 0.00000 & 0.00391 & -1.00000 \\\\\n",
      "Overall Learning & NEW & 0.00000 & 0.00391 & -1.00000 \\\\\n",
      "Perturbation Breakdown & ALL & 0.00000 & 0.00391 & -1.00000 \\\\\n",
      "Perturbation Breakdown & KNOWN & 0.00000 & 0.00391 & -1.00000 \\\\\n",
      "Perturbation Breakdown & NEW & 2.00000 & 0.01172 & -0.91111 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Merge p-values and effect sizes into one summary table\n",
    "df_merged = pd.merge(df_stats, df_effects_manual, on=[\"Test Group\", \"Subset\"])\n",
    "\n",
    "# Reorder columns for clarity\n",
    "df_merged = df_merged[[\n",
    "    \"Test Group\", \"Subset\", \"Wilcoxon Statistic\", \"p-value\", \"Effect Size (r)\"\n",
    "]]\n",
    "\n",
    "# Save to LaTeX\n",
    "latex_combined = df_merged.to_latex(index=False, float_format=\"%.5f\", caption=\"Wilcoxon test results with rank-biserial effect sizes for MSE comparisons across conditions.\", label=\"tab:wilcoxon_full_results\")\n",
    "print(latex_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b664a97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1452249/40297938.py:35: RuntimeWarning: divide by zero encountered in divide\n",
      "  R2 = np.where(tss > 1e-12, 1 - rss / tss, np.nan)  # shape (D,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "# WHAT DO WE WANT TO CALCULATE:\n",
    "# 1. MSE for each movement, by participant, for each perturbation condition (before/after)\n",
    "# 2. Pearson correlation for each movement for each target, by participant, for each perturbation condition (before/after)\n",
    "# 3. RSS and TSS for each movement for each target, by participant, for each perturbation condition (before/after)\n",
    "# 4. Fisher's Z transformation to aggregate the correlations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from numpy import arctanh, tanh\n",
    "\n",
    "# Setup\n",
    "data_folder = Path('/home/haptix/haptix/biomech_PCP/paper_utils/paper_data/trajectories')\n",
    "results = []  # Will hold all row dicts\n",
    "\n",
    "# Loop\n",
    "# for perturb in [True, False]:\n",
    "#     for condition in ['before', 'after']:\n",
    "#         for participant in online_participants:\n",
    "#             for movement in movements\n",
    "online_participants = [part for part in participants if 'P6' not in part]\n",
    "for participant in online_participants:\n",
    "    for perturb in [False, True]:\n",
    "        for condition in ['after', 'before']:\n",
    "            for movement in movements:\n",
    "                gt = np.load(data_folder / participant / movement / 'GT/pred.npy')        # (T, D)\n",
    "                pred = np.load(data_folder / participant / movement / f'perturb_{str(perturb)}/{condition}_online/pred.npy')\n",
    "\n",
    "\n",
    "                rss = np.sum((gt - pred)**2, axis=0)  # shape (D,)\n",
    "                tss = np.sum((gt - np.mean(gt, axis=0))**2, axis=0)  # shape (D,)\n",
    "                mse = np.mean((gt - pred)**2, axis=0)  # shape (D,)\n",
    "                corrs = np.array([np.corrcoef(gt[:, i], pred[:, i])[0, 1] for i in range(gt.shape[1])])  # (D,)\n",
    "                R2 = np.where(tss > 1e-12, 1 - rss / tss, np.nan)  # shape (D,)\n",
    "\n",
    "                for i, target in enumerate(targets):\n",
    "                    results.append({\n",
    "                        'Participant': participant,\n",
    "                        'Movement': movement,\n",
    "                        'Perturb': perturb,\n",
    "                        'Condition': condition,\n",
    "                        'Joint': target,\n",
    "                        'MSE': mse[i],\n",
    "                        'RSS': rss[i],\n",
    "                        'TSS': tss[i],\n",
    "                        'R2': R2[i],\n",
    "                        'Corr': corrs[i]\n",
    "                    })\n",
    "\n",
    "            #     # get the all joints value\n",
    "            #     results.append({\n",
    "            #         'Participant': participant,\n",
    "            #         'Movement': movement,\n",
    "            #         'Perturb': perturb,\n",
    "            #         'Condition': condition,\n",
    "            #         'Joint': 'All',\n",
    "            #         'MSE': np.mean(mse),\n",
    "            #         'RSS': np.sum(rss),\n",
    "            #         'TSS': np.sum(tss),\n",
    "            #         'R2': 1 - np.sum(rss) / np.sum(tss) if np.sum(tss) > 1e-12 else np.nan,\n",
    "            #         'Corr': np.NaN # we can't just aggregate!\n",
    "            #     })\n",
    "            \n",
    "            # # then we also want to get all of the above for the participant and perturbation condition\n",
    "            # results.append({\n",
    "            #     'Participant': participant,\n",
    "            #     'Movement': 'All',\n",
    "            #     'Perturb': perturb,\n",
    "            #     'Condition': condition,\n",
    "            #     'Joint': 'All',\n",
    "            #     'MSE': np.mean([res['MSE'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition]),\n",
    "            #     'RSS': np.sum([res['RSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition]),\n",
    "            #     'TSS': np.sum([res['TSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition]),\n",
    "            #     'R2': 1 - np.sum([res['RSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition]) / \n",
    "            #             np.sum([res['TSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition]) \n",
    "            #             if np.sum([res['TSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition]) > 1e-12 else np.nan,\n",
    "            #     'Corr': np.NaN  # we can't just aggregate!\n",
    "            # })\n",
    "\n",
    "            # # and also broken down by each joint across all movements like this\n",
    "            # for target in targets:\n",
    "            #     results.append({\n",
    "            #         'Participant': participant,\n",
    "            #         'Movement': 'All',\n",
    "            #         'Perturb': perturb,\n",
    "            #         'Condition': condition,\n",
    "            #         'Joint': target,\n",
    "            #         'MSE': np.mean([res['MSE'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition and res['Joint'] == target]),\n",
    "            #         'RSS': np.sum([res['RSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition and res['Joint'] == target]),\n",
    "            #         'TSS': np.sum([res['TSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition and res['Joint'] == target]),\n",
    "            #         'R2': 1 - np.sum([res['RSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition and res['Joint'] == target]) / \n",
    "            #                 np.sum([res['TSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition and res['Joint'] == target]) \n",
    "            #                 if np.sum([res['TSS'] for res in results if res['Participant'] == participant and res['Perturb'] == perturb and res['Condition'] == condition and res['Joint'] == target]) > 1e-12 else np.nan,\n",
    "            #         'Corr': np.NaN  # we can't just aggregate!\n",
    "            #     })\n",
    "\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save per-target metrics\n",
    "df.to_csv('all_performance_metrics.csv', index=False)\n",
    "\n",
    "# Replace extremely small TSS values to avoid divide-by-zero\n",
    "df['TSS_safe'] = df['TSS'].where(df['TSS'] > 1e-12, np.nan)\n",
    "\n",
    "# Compute participant  condition  perturb  joint aggregates (across movements)\n",
    "agg_joint = df[df['Movement'] != 'All'].groupby(['Participant', 'Perturb', 'Condition', 'Joint']).agg({\n",
    "    'MSE': 'mean',\n",
    "    'RSS': 'sum',\n",
    "    'TSS_safe': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "agg_joint['R2'] = 1 - agg_joint['RSS'] / agg_joint['TSS_safe']\n",
    "agg_joint['Movement'] = 'All'\n",
    "agg_joint['Corr'] = np.nan  # can't aggregate correlation directly\n",
    "\n",
    "# Compute participant  condition  perturb aggregates across all joints/movements\n",
    "agg_all = df[df['Movement'] != 'All'].groupby(['Participant', 'Perturb', 'Condition']).agg({\n",
    "    'MSE': 'mean',\n",
    "    'RSS': 'sum',\n",
    "    'TSS_safe': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "agg_all['R2'] = 1 - agg_all['RSS'] / agg_all['TSS_safe']\n",
    "agg_all['Movement'] = 'All'\n",
    "agg_all['Joint'] = 'All'\n",
    "agg_all['Corr'] = np.nan  # can't aggregate correlation\n",
    "agg_all = agg_all[['Participant', 'Perturb', 'Condition', 'Movement', 'Joint', 'MSE', 'RSS', 'TSS_safe', 'R2', 'Corr']]\n",
    "\n",
    "# Fix original df column to match new aggregated ones\n",
    "df['TSS_safe'] = df['TSS']\n",
    "df = df[['Participant', 'Perturb', 'Condition', 'Movement', 'Joint', 'MSE', 'RSS', 'TSS_safe', 'R2', 'Corr']]\n",
    "\n",
    "# Combine all\n",
    "df_final = pd.concat([df, agg_joint, agg_all], ignore_index=True)\n",
    "\n",
    "# Optional: save to CSV\n",
    "df_final.to_csv('aggregated_model_metrics.csv', index=False)\n",
    "\n",
    "\n",
    "# now we want to do some aggregations\n",
    "# Example aggregation: mean MSE per participant (can group by anything else too)\n",
    "# agg_mse = df.groupby(['Participant', 'Perturb', 'Condition']) \\\n",
    "#            .apply(lambda g: np.mean(g['MSE'])) \\\n",
    "#            .reset_index(name='Mean_MSE')\n",
    "# agg_mse.to_csv('mse_participant.csv', index=False)\n",
    "\n",
    "# need to get a bit more clever for correlations and R^2 because \n",
    "\n",
    "\n",
    "# # Compute Fisher-Z aggregated correlation\n",
    "# df['Z'] = arctanh(df['Corr'])  # Fisher Z-transform\n",
    "\n",
    "# # Example aggregation: mean z per participant (can group by anything else too)\n",
    "# agg_corr = df.groupby(['Participant', 'Perturb', 'Condition']) \\\n",
    "#              .apply(lambda g: tanh(np.average(g['Z']))) \\\n",
    "#              .reset_index(name='FisherZ_Aggregated_Corr')\n",
    "\n",
    "# agg_corr.to_csv('aggregated_correlations.csv', index=False)\n",
    "\n",
    "# # Example aggregation: R^2 per participant (sum RSS/TSS)\n",
    "# agg_r2 = df.groupby(['Participant', 'Perturb', 'Condition']) \\\n",
    "#            .apply(lambda g: 1 - g['RSS'].sum() / g['TSS'].sum()) \\\n",
    "#            .reset_index(name='Global_R2')\n",
    "\n",
    "# agg_r2.to_csv('aggregated_r2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c205afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from numpy import arctanh, tanh\n",
    "\n",
    "rows = []\n",
    "\n",
    "online_participants = [p for p in participants if 'P6' not in p]\n",
    "\n",
    "for perturb in [True, False]:\n",
    "    for condition in ['before', 'after']:\n",
    "        for participant in online_participants:\n",
    "            gt_cat = []\n",
    "            pred_cat = []\n",
    "\n",
    "            for movement in movements:\n",
    "                gt = np.load(data_folder / participant / movement / 'GT/pred.npy')\n",
    "                pred = np.load(data_folder / participant / movement / f'perturb_{str(perturb)}/{condition}_online/pred.npy')\n",
    "                gt_cat.append(gt)\n",
    "                pred_cat.append(pred)\n",
    "\n",
    "            gt_cat = np.concatenate(gt_cat, axis=0)\n",
    "            pred_cat = np.concatenate(pred_cat, axis=0)\n",
    "\n",
    "            # Calculate per-target Pearson r and apply Fisher z\n",
    "            r_vals = np.array([np.corrcoef(gt_cat[:, i], pred_cat[:, i])[0, 1] for i in range(len(targets))])\n",
    "            z_vals = arctanh(r_vals)  # Fisher transform\n",
    "\n",
    "            # No aggregation here  just transform back\n",
    "            r_fisher_corrected = tanh(z_vals)\n",
    "\n",
    "            row = {\n",
    "                'Participant': participant,\n",
    "                'Perturb': perturb,\n",
    "                'Condition': condition\n",
    "            }\n",
    "            for target, r in zip(targets, r_fisher_corrected):\n",
    "                row[target] = r\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "# Final DataFrame: wide-form with one row per (participant, perturb, condition)\n",
    "df_corr_fisher = pd.DataFrame(rows)\n",
    "\n",
    "# Optional: save to CSV\n",
    "df_corr_fisher.to_csv('corr_fisher_corrected_by_joint.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
