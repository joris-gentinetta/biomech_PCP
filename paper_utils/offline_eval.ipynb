{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062232c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import os\n",
    "import yaml\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "import torch\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "from helpers.predict_utils import Config, get_data\n",
    "from helpers.models import TimeSeriesRegressorWrapper\n",
    "from paper_utils.utils import participants\n",
    "\n",
    "allow_tf32 = True\n",
    "if allow_tf32:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88f5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing P_149...\n",
      "\tPerturbation: True\n",
      "<helpers.predict_utils.Config object at 0x7ff5741f03d0>\n",
      "<helpers.predict_utils.Config object at 0x7ff5741f03d0>\n",
      "<helpers.predict_utils.Config object at 0x7ff5741f03d0>\n",
      "<helpers.predict_utils.Config object at 0x7ff5741f03d0>\n",
      "<helpers.predict_utils.Config object at 0x7ff5741f03d0>\n",
      "<helpers.predict_utils.Config object at 0x7ff5741f03d0>\n",
      "<helpers.predict_utils.Config object at 0x7ff5741f03d0>\n",
      "<helpers.predict_utils.Config object at 0x7ff5741f03d0>\n",
      "<helpers.predict_utils.Config object at 0x7ff5741f03d0>\n",
      "{'name': 'P_149', 'recordings': ['thumbFlEx', 'thumbAbAd', 'indexFlEx', 'mrpFlEx', 'fingersFlEx', 'wristFlEx', 'handOpCl', 'pinchOpCl', 'pointOpCl'], 'test_recordings': ['keyOpCl', 'wristFlHandCl', 'indexFlDigitsEx'], 'features': [('emg', '0'), ('emg', '1'), ('emg', '2'), ('emg', '4'), ('emg', '10'), ('emg', '11'), ('emg', '12'), ('emg', '13')], 'early_stopping_patience': 1000, 'early_stopping_delta': 0.05, 'learning_rate': 0.005, 'n_epochs': 1000, 'seq_len': 64, 'targets': [('Left', 'indexAng'), ('Left', 'midAng'), ('Left', 'ringAng'), ('Left', 'pinkyAng'), ('Left', 'thumbInPlaneAng'), ('Left', 'thumbOutPlaneAng'), ('Left', 'wristFlex')], 'warmup_steps': 0, 'batch_size': 8, 'wandb_mode': 'offline', 'wandb_project': 'study_participants', 'model_type': 'ModularModel', 'activation_model': {'model_type': 'DenseNet', 'hidden_size': 64, 'n_layers': 3, 'n_freeze_epochs': 0}, 'muscle_model': {'model_type': 'PhysMuscleModel', 'n_freeze_epochs': 1}, 'joint_model': {'model_type': 'PhysJointModel', 'n_freeze_epochs': 1, 'speed_mode': False}, 'person_dir': 'P_149', 'intact_hand': 'Left'}\n",
      "\t\tCondition: before\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/P_149/online_trials/perturb/models/P_149-online_0.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m condition \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monline_trials\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mperson_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-online_0.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     model\u001b[38;5;241m.\u001b[39mload(join(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, person_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monline_trials\u001b[39m\u001b[38;5;124m'\u001b[39m, experiment_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperson_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-online_last.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/haptix/biomech_PCP/helpers/models.py:804\u001b[0m, in \u001b[0;36mTimeSeriesRegressorWrapper.load\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(\n\u001b[0;32m--> 804\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m     )  \u001b[38;5;66;03m# note that we load to cpu\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/PCP/lib/python3.8/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/PCP/lib/python3.8/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/PCP/lib/python3.8/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/P_149/online_trials/perturb/models/P_149-online_0.pt'"
     ]
    }
   ],
   "source": [
    "online_participants = [part for part in participants if 'P6_' not in part]\n",
    "\n",
    "config_name = 'modular_online'\n",
    "sampling_frequency = 60    \n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "for person_dir in online_participants:\n",
    "    print(f'Processing {person_dir}...')\n",
    "    with open(join('data', person_dir, 'configs', f'{config_name}.yaml'), 'r') as file:\n",
    "        wandb_config = yaml.safe_load(file)\n",
    "        config = Config(wandb_config)\n",
    "    \n",
    "    data_dirs = [join('data', person_dir, 'recordings', recording, 'experiments', '1') for recording in config.recordings]\n",
    "    test_dirs = [join('data', person_dir, 'recordings', recording, 'experiments', '1') for recording in config.test_recordings] if config.test_recordings is not None else []\n",
    "    \n",
    "    intact_hand = config.targets[0][0]\n",
    "    config.person_dir = person_dir\n",
    "    config.intact_hand = intact_hand\n",
    "\n",
    "    for perturb in [True, False]:\n",
    "        print(f'\\tPerturbation: {perturb}')\n",
    "        experiment_name = f'non_' if not perturb else '' + 'perturb'\n",
    "        perturb_file = join('data', person_dir, 'online_trials', experiment_name, 'perturber.npy')\n",
    "        trainsets, valsets, combined_sets, testsets = get_data(config, data_dirs, intact_hand, test_dirs=test_dirs, perturb_file=perturb_file)\n",
    "        \n",
    "        model = TimeSeriesRegressorWrapper(device=device, input_size=len(config.features), output_size=len(config.targets), **config.to_dict())\n",
    "        for condition in ['before', 'after']:\n",
    "            print(f'\\t\\tCondition: {condition}')\n",
    "\n",
    "            model.to('cpu')\n",
    "            if condition == 'before':\n",
    "                model.load(join('data', person_dir, 'online_trials', experiment_name, 'models', f'{person_dir}-online_0.pt'))\n",
    "            else:\n",
    "                model.load(join('data', person_dir, 'online_trials', experiment_name, 'models', f'{person_dir}-online_last.pt'))\n",
    "\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            \n",
    "            for recording, testset in zip(config.test_recordings, testsets):\n",
    "                pred = model.predict(testset, config.features, config.targets).squeeze(0).to(\"cpu\").detach().numpy()\n",
    "                save_dir = join('data', person_dir, 'recordings', recording, 'experiments', '1')\n",
    "                testset[config.targets] = pred\n",
    "                testset.to_parquet(save_dir, f\"pred_angles-{config.name}_{condition}Online_{experiment_name}.parquet\")\n",
    "                \n",
    "            for recording, valset in zip(config.recordings, valsets):\n",
    "                pred = model.predict(valset, config.features, config.targets).squeeze(0).to(\"cpu\").detach().numpy()\n",
    "                save_dir = join('data', person_dir, 'recordings', recording, 'experiments', '1')\n",
    "                valset[config.targets] = pred\n",
    "                valset.to_parquet(save_dir, f\"pred_angles-{config.name}_{condition}Online_{experiment_name}.parquet\")                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
