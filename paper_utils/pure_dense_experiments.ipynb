{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "from deepdiff import DeepDiff\n",
    "from utils import (\n",
    "    amputees,\n",
    "    channel_names,\n",
    "    intact,\n",
    "    participants,\n",
    "    recordings,\n",
    "    targets,\n",
    "    test_recordings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beded93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_plots_path = Path(\"/Users/jorisg/Desktop/upper_limb/paper_figures_revision\")\n",
    "base_dir = Path().resolve().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-10, 10, 500)\n",
    "softplus = np.log1p(np.exp(x))  # log(1 + exp(x))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, softplus, label=\"softplus(x)\", linewidth=2)\n",
    "plt.title(\"Softplus Activation Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"softplus(x)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d5a7e7",
   "metadata": {},
   "source": [
    "-> P7_453 is Right, all others are Left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet experiments\n",
    "base_config_path = base_dir / \"data/<person_ID>/configs/modular_initialization.yaml\"\n",
    "with open(base_config_path, \"r\") as f:\n",
    "    base_config_template = yaml.safe_load(f)\n",
    "\n",
    "base_config_template[\"parameters\"].pop(\"activation_model\", None)\n",
    "base_config_template[\"parameters\"].pop(\"muscle_model\", None)\n",
    "base_config_template[\"parameters\"].pop(\"joint_model\", None)\n",
    "\n",
    "\n",
    "base_config_template[\"parameters\"][\"model_type\"] = {\"value\": \"DenseNet\"}\n",
    "base_config_template[\"parameters\"][\"n_freeze_epochs\"] = {\"value\": 0}\n",
    "base_config_template[\"parameters\"][\"hidden_size\"] = {\"value\": 64}\n",
    "base_config_template[\"parameters\"][\"n_layers\"] = {\"values\": [3, 4, 5, 6]}\n",
    "# base_config_template[\"parameters\"][\"init\"] = {\"values\": [\"default\", \"xavier_normal\"]}\n",
    "base_config_template[\"parameters\"][\"init\"] = {\"value\": \"default_all\"}\n",
    "\n",
    "base_config_template[\"parameters\"][\"state_mode\"] = {\"value\": \"stateless\"}\n",
    "\n",
    "base_config_template[\"parameters\"][\"wandb_project\"][\"value\"] = \"pure_dense_experiments\"\n",
    "base_config_template[\"parameters\"][\"learning_rate\"][\"values\"] = [\n",
    "    0.1,\n",
    "    0.01,\n",
    "    0.001,\n",
    "    0.0001,\n",
    "]\n",
    "base_config_template[\"parameters\"][\"tanh\"] = {\"values\": [False, True]}\n",
    "base_config_template[\"parameters\"][\"tanh\"].pop(\"value\", None)\n",
    "\n",
    "base_config_template[\"parameters\"][\"learning_rate\"].pop(\"value\", None)\n",
    "\n",
    "base_config_template[\"parameters\"][\"dummy_repetition\"][\"value\"] = 1\n",
    "base_config_template[\"parameters\"][\"dummy_repetition\"].pop(\"values\", None)\n",
    "\n",
    "for participant in participants:\n",
    "    participant_config_path = base_dir / f\"data/{participant}/configs/pure_dense.yaml\"\n",
    "\n",
    "    base_config = base_config_template.copy()\n",
    "    base_config[\"name\"] = participant\n",
    "\n",
    "    if participant == \"P7_453\":\n",
    "        base_config[\"parameters\"][\"targets\"][\"value\"] = [\n",
    "            [\"Right\", joint]\n",
    "            for _, joint in base_config[\"parameters\"][\"targets\"][\"value\"]\n",
    "        ]\n",
    "    else:\n",
    "        base_config[\"parameters\"][\"targets\"][\"value\"] = [\n",
    "            [\"Left\", joint]\n",
    "            for _, joint in base_config[\"parameters\"][\"targets\"][\"value\"]\n",
    "        ]\n",
    "    with open(participant_config_path, \"w\") as f:\n",
    "        yaml.dump(base_config, f)\n",
    "    print(f\"Copied config to {participant_config_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for participant in participants:\n",
    "    hand = \"Right\" if participant == \"P7_453\" else \"Left\"\n",
    "    print(f\"Running training for {participant} with intact hand {hand}\")\n",
    "\n",
    "    # Run the command using subprocess\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"python\",\n",
    "            base_dir / \"s4_train.py\",\n",
    "            \"--person_dir\",\n",
    "            participant,\n",
    "            \"--intact_hand\",\n",
    "            hand,\n",
    "            \"--config_name\",\n",
    "            \"pure_dense\",\n",
    "            \"-hs\",\n",
    "        ],\n",
    "        cwd=base_dir,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574dfb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"MIT_biomech/pure_dense_experiments\")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame(\n",
    "    {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    ")\n",
    "\n",
    "runs_df_archive = copy.deepcopy(runs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df[\"total_val_loss\"] = runs_df[\"summary\"].apply(\n",
    "    lambda x: x.get(\"total_val_loss\", None)\n",
    ")\n",
    "runs_df[\"total_test_loss\"] = runs_df[\"summary\"].apply(\n",
    "    lambda x: x.get(\"total_test_loss\", None)\n",
    ")\n",
    "# parameters: \"learning_rate\", \"init\", \"n_layers\", \"tanh\"\n",
    "runs_df[\"learning_rate\"] = runs_df[\"config\"].apply(\n",
    "    lambda x: x.get(\"learning_rate\", None)\n",
    ")\n",
    "runs_df[\"init\"] = runs_df[\"config\"].apply(lambda x: x.get(\"init\", None))\n",
    "runs_df[\"n_layers\"] = runs_df[\"config\"].apply(lambda x: x.get(\"n_layers\", None))\n",
    "runs_df[\"tanh\"] = runs_df[\"config\"].apply(lambda x: x.get(\"tanh\", None))\n",
    "\n",
    "runs_df[\"n_epochs\"] = runs_df[\"summary\"].apply(lambda x: x.get(\"_step\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03205a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df.n_epochs.unique()\n",
    "# none of the runs failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07421056",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df.drop(columns=[\"summary\", \"config\"], inplace=True)\n",
    "runs_df.rename(columns={\"name\": \"participant\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc311ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df[\"total_combined_loss\"] = (\n",
    "    runs_df[\"total_val_loss\"] * 9 + runs_df[\"total_test_loss\"] * 3\n",
    ") / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amputee = runs_df[runs_df[\"participant\"].isin(amputees)].copy()\n",
    "df_intact = runs_df[runs_df[\"participant\"].isin(intact)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddcec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by participant and init, then get the mean and std of total_val_loss\n",
    "parameters = [\"learning_rate\", \"init\", \"n_layers\", \"tanh\"]\n",
    "grouped_df = (\n",
    "    runs_df.groupby(parameters)\n",
    "    .agg(\n",
    "        mean_val_loss=(\"total_val_loss\", \"mean\"),\n",
    "        std_val_loss=(\"total_val_loss\", \"std\"),\n",
    "        mean_test_loss=(\"total_test_loss\", \"mean\"),\n",
    "        std_test_loss=(\"total_test_loss\", \"std\"),\n",
    "        mean_combined_loss=(\"total_combined_loss\", \"mean\"),\n",
    "        std_combined_loss=(\"total_combined_loss\", \"std\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "grouped_df_amputee = (\n",
    "    df_amputee.groupby(parameters)\n",
    "    .agg(\n",
    "        mean_val_loss=(\"total_val_loss\", \"mean\"),\n",
    "        std_val_loss=(\"total_val_loss\", \"std\"),\n",
    "        mean_test_loss=(\"total_test_loss\", \"mean\"),\n",
    "        std_test_loss=(\"total_test_loss\", \"std\"),\n",
    "        mean_combined_loss=(\"total_combined_loss\", \"mean\"),\n",
    "        std_combined_loss=(\"total_combined_loss\", \"std\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "grouped_df_intact = (\n",
    "    df_intact.groupby(parameters)\n",
    "    .agg(\n",
    "        mean_val_loss=(\"total_val_loss\", \"mean\"),\n",
    "        std_val_loss=(\"total_val_loss\", \"std\"),\n",
    "        mean_test_loss=(\"total_test_loss\", \"mean\"),\n",
    "        std_test_loss=(\"total_test_loss\", \"std\"),\n",
    "        mean_combined_loss=(\"total_combined_loss\", \"mean\"),\n",
    "        std_combined_loss=(\"total_combined_loss\", \"std\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c79a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_amputee.loc[42, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b231ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_intact.loc[42, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e701de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
